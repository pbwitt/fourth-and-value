{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cbcae0",
   "metadata": {},
   "source": [
    "\n",
    "# Fourth & Value — QC Slim: Actuals vs Model\n",
    "\n",
    "**Why this exists:** Your `data/actuals/weekX.csv` is already in **long format** (`player_key,name_std,market_std,side,point,actual_value,result`).\n",
    "So we don't need to hunt for per-stat columns; we can grade directly. This notebook is the **clean minimal path** with an\n",
    "optional **stats backfill** for O/U if the actuals file doesn't include those yet.\n",
    "\n",
    "**Outputs**\n",
    "- `data/eval/grades_week{WEEK}.csv` (row-level graded)\n",
    "- `data/eval/grades_week{WEEK}_by_market.csv`\n",
    "- `data/eval/coverage_week{WEEK}.csv`\n",
    "- `data/eval/calibration_week{WEEK}.csv`\n",
    "- `data/eval/qc_summary_week{WEEK}.json` and `.txt`\n",
    "\n",
    "> Created: 2025-09-16 19:38 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbc5cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'SEASON': 2025, 'WEEK': 2}\n",
      "files: props_with_model_week2.csv week2.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Parameters ===============================================================\n",
    "SEASON = 2025\n",
    "WEEK   = 2\n",
    "\n",
    "# Files\n",
    "PROPS_CSV   = f\"props_with_model_week{WEEK}.csv\"\n",
    "ACTUALS_CSV = f\"week{WEEK}.csv\"\n",
    "STATS_FILE  = \"weekly_player_stats_2025.parquet\"  # for optional backfill\n",
    "\n",
    "# Toggle: backfill O/U actuals from weekly stats if actuals lacks them\n",
    "USE_STATS_BACKFILL = True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "import os, math, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EVAL_DIR = Path(\"data/eval\"); EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"params:\", dict(SEASON=SEASON, WEEK=WEEK))\n",
    "print(\"files:\", PROPS_CSV, ACTUALS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0e0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[props] shape: (2673, 24)   [actuals] shape: (160, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            game_id         commence_time       home_team  \\\n",
       " 0  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       " 1  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       " \n",
       "               away_team                                   game   bookmaker  \\\n",
       " 0  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       " 1  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       " \n",
       "   bookmaker_title         market market_std        player  ...   player_key  \\\n",
       " 0      DraftKings  player_1st_td   first_td  Bucky Irving  ...  buckyirving   \n",
       " 1      DraftKings  player_1st_td   first_td    Nick Chubb  ...    nickchubb   \n",
       " \n",
       "    point_key  mu sigma lam  mkt_prob  model_prob  edge_bps  season  week  \n",
       " 0        NaN NaN   NaN NaN  0.153846         NaN       NaN    2025     2  \n",
       " 1        NaN NaN   NaN NaN  0.142857         NaN       NaN    2025     2  \n",
       " \n",
       " [2 rows x 24 columns],\n",
       "   player_key name  market_std side  point  actual_value  result\n",
       " 0  joshallen  yes  anytime_td  yes    NaN           0.0     0.0\n",
       " 1  joshallen  yes  anytime_td   no    NaN           0.0     1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === Load ====================================================================\n",
    "dfp = pd.read_csv(PROPS_CSV)\n",
    "dfa = pd.read_csv(ACTUALS_CSV)\n",
    "print(\"[props] shape:\", dfp.shape, \"  [actuals] shape:\", dfa.shape)\n",
    "dfp.head(2), dfa.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b311718b-51c9-4fc2-82e4-a1523cde2c5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[^a-z]\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(s).lower())\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 0) Ensure join keys exist on stats\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mname_std\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stats.columns:\n\u001b[32m     13\u001b[39m     name_col_s = \u001b[33m\"\u001b[39m\u001b[33mplayer_display_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mplayer_display_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stats.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mplayer_name\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     stats = stats.copy()\n",
      "\u001b[31mNameError\u001b[39m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd, unicodedata, re\n",
    "\n",
    "# Use your normalizer (same one used in props)\n",
    "try:\n",
    "    from scripts.common_markets import std_name\n",
    "except Exception:\n",
    "    def std_name(s):\n",
    "        s = unicodedata.normalize(\"NFKD\", str(s)).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "        return re.sub(r\"[^a-z]\",\"\", str(s).lower())\n",
    "\n",
    "# 0) Ensure join keys exist on stats\n",
    "if \"name_std\" not in stats.columns:\n",
    "    name_col_s = \"player_display_name\" if \"player_display_name\" in stats.columns else \"player_name\"\n",
    "    stats = stats.copy()\n",
    "    stats[\"name_std\"] = stats[name_col_s].map(std_name)\n",
    "if \"team_std\" not in stats.columns and \"team\" in stats.columns:\n",
    "    stats[\"team_std\"] = stats[\"team\"].astype(str).str.upper()\n",
    "if \"position\" not in stats.columns:\n",
    "    stats[\"position\"] = \"UNK\"\n",
    "\n",
    "# 1) Map your normalized markets → stats columns\n",
    "OU_MAP = {\n",
    "    \"pass_yds\":          \"passing_yards\",\n",
    "    \"rush_yds\":          \"rushing_yards\",\n",
    "    \"recv_yds\":          \"receiving_yards\",\n",
    "    \"receptions\":        \"receptions\",\n",
    "    \"pass_attempts\":     \"attempts\",\n",
    "    \"pass_completions\":  \"completions\",\n",
    "    \"rush_attempts\":     \"carries\",\n",
    "    \"pass_tds\":          \"passing_tds\",\n",
    "    # note: nflverse uses 'passing_interceptions'\n",
    "    \"pass_ints\":         \"passing_interceptions\",\n",
    "    # only include these if your stats file actually has them:\n",
    "    # \"reception_longest\": \"reception_longest\",\n",
    "    # \"rush_longest\":      \"rush_longest\",\n",
    "}\n",
    "\n",
    "# keep only columns that exist in stats\n",
    "have = {mkt: col for mkt, col in OU_MAP.items() if col in stats.columns}\n",
    "inv = {col: mkt for mkt, col in have.items()}\n",
    "value_cols = list(inv.keys())\n",
    "\n",
    "# 2) Melt wide → long: one value column for *all* markets\n",
    "s_long = (\n",
    "    stats[[\"name_std\", \"team_std\", \"position\"] + value_cols]\n",
    "      .melt(id_vars=[\"name_std\",\"team_std\",\"position\"],\n",
    "            value_vars=value_cols,\n",
    "            var_name=\"stat_col\",\n",
    "            value_name=\"actual_value\")\n",
    "      .assign(market_std=lambda d: d[\"stat_col\"].map(inv))\n",
    "      .drop(columns=[\"stat_col\"])\n",
    "      .dropna(subset=[\"market_std\"])      # safety: only mapped markets\n",
    ")\n",
    "\n",
    "# Optional: if you only want (name_std, market_std, actual_value)\n",
    "s_long_min = s_long[[\"name_std\", \"market_std\", \"actual_value\"]]\n",
    "\n",
    "print(s_long.head(10))\n",
    "print(s_long_min.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acaca714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge keys: ['player_key', 'market_std']\n",
      "[merge] rows: 2829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>commence_time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>game</th>\n",
       "      <th>bookmaker</th>\n",
       "      <th>bookmaker_title</th>\n",
       "      <th>market</th>\n",
       "      <th>market_std</th>\n",
       "      <th>player</th>\n",
       "      <th>...</th>\n",
       "      <th>mkt_prob</th>\n",
       "      <th>model_prob</th>\n",
       "      <th>edge_bps</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>name_act</th>\n",
       "      <th>side</th>\n",
       "      <th>point_act</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_1st_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_1st_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Nick Chubb</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_1st_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Nico Collins</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            game_id         commence_time       home_team  \\\n",
       "0  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "1  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "2  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "\n",
       "              away_team                                   game   bookmaker  \\\n",
       "0  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "1  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "2  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "\n",
       "  bookmaker_title         market market_std        player  ...  mkt_prob  \\\n",
       "0      DraftKings  player_1st_td   first_td  Bucky Irving  ...  0.153846   \n",
       "1      DraftKings  player_1st_td   first_td    Nick Chubb  ...  0.142857   \n",
       "2      DraftKings  player_1st_td   first_td  Nico Collins  ...  0.125000   \n",
       "\n",
       "   model_prob  edge_bps season week  name_act  side  point_act  actual_value  \\\n",
       "0         NaN       NaN   2025    2       NaN   NaN        NaN           NaN   \n",
       "1         NaN       NaN   2025    2       NaN   NaN        NaN           NaN   \n",
       "2         NaN       NaN   2025    2       NaN   NaN        NaN           NaN   \n",
       "\n",
       "   result  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === Merge with robust fallbacks =============================================\n",
    "keys = []\n",
    "if all(k in dfp.columns for k in [\"player_key\",\"market_std\",\"point_key\"]) and \\\n",
    "   all(k in dfa.columns for k in [\"player_key\",\"market_std\",\"point_key\"]):\n",
    "    keys = [\"player_key\",\"market_std\",\"point_key\"]\n",
    "elif all(k in dfp.columns for k in [\"player_key\",\"market_std\"]) and \\\n",
    "     all(k in dfa.columns for k in [\"player_key\",\"market_std\"]):\n",
    "    keys = [\"player_key\",\"market_std\"]\n",
    "else:\n",
    "    keys = [\"name_std\",\"market_std\"]\n",
    "    if \"point_key\" in dfp.columns and \"point_key\" in dfa.columns:\n",
    "        keys.append(\"point_key\")\n",
    "\n",
    "print(\"merge keys:\", keys)\n",
    "merged = dfp.merge(dfa, how=\"left\", on=[k for k in keys if k in dfp.columns and k in dfa.columns], suffixes=(\"\", \"_act\"))\n",
    "print(\"[merge] rows:\", len(merged))\n",
    "merged.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e998e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Canonicalize line & side ================================================\n",
    "def first_existing_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "line_src = first_existing_col(merged, [\"line\",\"point\",\"point_key\",\"book_line\",\"offer_line\",\"line_disp\"])\n",
    "if line_src is None:\n",
    "    merged[\"line\"] = np.nan\n",
    "else:\n",
    "    merged[\"line\"] = merged[line_src]\n",
    "    if merged[\"line\"].dtype == object:\n",
    "        merged[\"line\"] = pd.to_numeric(\n",
    "            merged[\"line\"].astype(str).str.extract(r\"(-?\\d+(?:\\.\\d+)?)\", expand=False),\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "if \"side\" not in merged.columns:\n",
    "    guess = first_existing_col(merged, [\"side\",\"bet\",\"selection\",\"wager\",\"pick\"])\n",
    "    merged[\"side\"] = merged[guess] if guess else np.nan\n",
    "merged[\"side\"] = merged[\"side\"].astype(str).str.lower().str.extract(r\"(over|under|yes|no)\", expand=False)\n",
    "\n",
    "print(\"[canon] done. has line:\", merged[\"line\"].notna().mean(), \" has side:\", merged[\"side\"].notna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b96fa-b1fe-42d0-9072-af84e09e7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = next((c for c in [\"player_display_name\",\"player\"] if c in stats.columns), None)\n",
    "if not name_col:\n",
    "    raise KeyError(\"stats is missing a player name column\")\n",
    "stats = stats.copy()\n",
    "stats[\"name_std\"] = stats[name_col].map(std_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d87e3-e4df-4772-a718-95c22b8c0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c625841-2028-4c8a-8d23-9c9d9131f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beda3c5-cc4c-4e4c-b2e3-bde823110f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eaf2a9c-5bf7-4f78-aa9d-5e927091a59a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1) Join stats → merged on (name_std, market_std)\u001b[39;00m\n\u001b[32m      4\u001b[39m cols = [\u001b[33m\"\u001b[39m\u001b[33mname_std\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmarket_std\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mactual_value\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mteam_std\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m s_long.columns:\n\u001b[32m      6\u001b[39m     cols.append(\u001b[33m\"\u001b[39m\u001b[33mteam_std\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m smin = s_long[cols].copy()\n",
      "\u001b[31mNameError\u001b[39m: name 's_long' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) Join stats → merged on (name_std, market_std)\n",
    "cols = [\"name_std\", \"market_std\", \"actual_value\"]\n",
    "if \"team_std\" in s_long.columns:\n",
    "    cols.append(\"team_std\")\n",
    "smin = s_long[cols].copy()\n",
    "\n",
    "merged = merged.merge(\n",
    "    smin,\n",
    "    on=[\"name_std\", \"market_std\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_stats\")  # stats value becomes 'actual_value_stats'\n",
    ")\n",
    "\n",
    "# 2) (Optional but recommended) Drop mismatched teams to avoid same-name collisions\n",
    "if \"team_std\" in merged.columns:\n",
    "    home = merged[\"home_team\"].astype(str).str.upper()\n",
    "    away = merged[\"away_team\"].astype(str).str.upper()\n",
    "    bad = merged[\"team_std\"].notna() & ~merged[\"team_std\"].isin(home.combine(away, lambda h, a: {h, a}))\n",
    "    # vectorized version:\n",
    "    bad = merged[\"team_std\"].notna() & ~(\n",
    "        merged[\"team_std\"].eq(home) | merged[\"team_std\"].eq(away)\n",
    "    )\n",
    "    merged.loc[bad, \"actual_value_stats\"] = np.nan\n",
    "\n",
    "# 3) Fill only O/U rows that are missing actuals\n",
    "OU_MARKETS = {\n",
    "    \"pass_yds\",\"rush_yds\",\"recv_yds\",\"receptions\",\n",
    "    \"pass_attempts\",\"pass_completions\",\"rush_attempts\",\n",
    "    \"pass_tds\",\"pass_ints\",\"reception_longest\",\"rush_longest\"\n",
    "}\n",
    "need = merged[\"market_std\"].isin(OU_MARKETS) & merged[\"actual_value\"].isna()\n",
    "merged.loc[need, \"actual_value\"] = merged.loc[need, \"actual_value\"].fillna(\n",
    "    merged.loc[need, \"actual_value_stats\"]\n",
    ")\n",
    "\n",
    "# 4) Cleanup\n",
    "if \"actual_value_stats\" in merged.columns:\n",
    "    merged.drop(columns=[\"actual_value_stats\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87983d-9d63-4eb4-9476-bd76a0ca3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe325dc-6f1d-4ac6-b481-4245f8acbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OU_MARKETS = {\n",
    "    \"pass_yds\",\"rush_yds\",\"recv_yds\",\"receptions\",\n",
    "    \"pass_attempts\",\"pass_completions\",\"rush_attempts\",\n",
    "    \"pass_tds\",\"pass_ints\",\"reception_longest\",\"rush_longest\"\n",
    "}\n",
    "ou = merged[\"market_std\"].isin(OU_MARKETS)\n",
    "\n",
    "print(\"[O/U rows]\", ou.sum())\n",
    "print(\"[O/U with actual]\", merged.loc[ou, \"actual_value\"].notna().sum())\n",
    "\n",
    "# per-market audit\n",
    "audit = (merged.loc[ou, [\"market_std\",\"line\",\"actual_value\"]]\n",
    "         .assign(has_line=lambda d: d[\"line\"].notna(),\n",
    "                 has_actual=lambda d: d[\"actual_value\"].notna())\n",
    "         .groupby(\"market_std\")\n",
    "         .agg(rows=(\"market_std\",\"size\"),\n",
    "              with_line=(\"has_line\",\"sum\"),\n",
    "              with_actual=(\"has_actual\",\"sum\"))\n",
    "         .assign(still_missing=lambda d: d[\"with_line\"]-d[\"with_actual\"])\n",
    "         .sort_index())\n",
    "print(audit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25c52f-43be-412b-9eef-e05d6bb107b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you load stats and filter to WEEK/SEASON:\n",
    "import re, unicodedata, numpy as np, pandas as pd\n",
    "\n",
    "def std_name(s):\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s)).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return re.sub(r\"[^a-z]\", \"\", str(s).lower())\n",
    "\n",
    "# 1) Ensure name_std (and a team if available) on stats\n",
    "name_col = next((c for c in [\"player_name\",\"player_display_name\",\"player\"] if c in stats.columns), None)\n",
    "if not name_col:\n",
    "    raise KeyError(\"stats is missing a player name column\")\n",
    "stats = stats.copy()\n",
    "stats[\"name_std\"] = stats[name_col].map(std_name)\n",
    "team_stats = next((c for c in [\"recent_team\",\"team\",\"posteam\"] if c in stats.columns), None)\n",
    "if team_stats: stats[\"team_std\"] = stats[team_stats].astype(str).str.upper()\n",
    "\n",
    "# 2) Keep only the stat columns we can map\n",
    "BACKFILL_MAP = {\n",
    "    \"pass_yds\":         \"passing_yards\",\n",
    "    \"rush_yds\":         \"rushing_yards\",\n",
    "    \"recv_yds\":         \"receiving_yards\",\n",
    "    \"receptions\":       \"receptions\",\n",
    "    \"pass_attempts\":    \"attempts\",\n",
    "    \"pass_completions\": \"completions\",\n",
    "    \"rush_attempts\":    \"carries\",\n",
    "    \"pass_tds\":         \"passing_tds\",\n",
    "    \"pass_ints\":        \"interceptions\",\n",
    "    \"reception_longest\":\"reception_longest\",\n",
    "    \"rush_longest\":     \"rush_longest\",\n",
    "}\n",
    "have_map = {mkt: col for mkt, col in BACKFILL_MAP.items() if col in stats.columns}\n",
    "use_cols = [\"name_std\"] + ([\"team_std\"] if \"team_std\" in stats.columns else []) + sorted(have_map.values())\n",
    "use = stats.loc[:, use_cols].drop_duplicates()\n",
    "\n",
    "# 3) Ensure merged has compatible join cols\n",
    "if \"name_std\" not in merged.columns:\n",
    "    name_col_m = next((c for c in [\"player\",\"player_name\",\"player_display_name\",\"name\"] if c in merged.columns), None)\n",
    "    if not name_col_m: raise KeyError(\"merged lacks a name column to build name_std\")\n",
    "    merged[\"name_std\"] = merged[name_col_m].map(std_name)\n",
    "team_merged = next((c for c in [\"team\",\"recent_team\",\"posteam\"] if c in merged.columns), None)\n",
    "if team_merged:\n",
    "    merged[\"team_std\"] = merged[team_merged].astype(str).str.upper()\n",
    "\n",
    "# 4) For each market, fill actual_value by name (and team if both sides have it)\n",
    "if \"actual_value\" not in merged.columns:\n",
    "    merged[\"actual_value\"] = np.nan\n",
    "\n",
    "fills = {}\n",
    "for mkt, stat_col in have_map.items():\n",
    "    mask = (merged[\"market_std\"].eq(mkt)) & merged[\"line\"].notna()\n",
    "    if not mask.any(): continue\n",
    "    left = merged.loc[mask, [\"name_std\"] + ([\"team_std\"] if \"team_std\" in merged.columns and \"team_std\" in use.columns else [])]\n",
    "    right = use[[\"name_std\"] + ([\"team_std\"] if \"team_std\" in merged.columns and \"team_std\" in use.columns else []) + [stat_col]]\n",
    "    sub = left.merge(right, on=[\"name_std\"] + ([\"team_std\"] if \"team_std\" in left.columns and \"team_std\" in right.columns else []), how=\"left\")\n",
    "    before = merged.loc[mask, \"actual_value\"].isna().sum()\n",
    "    merged.loc[mask, \"actual_value\"] = merged.loc[mask, \"actual_value\"].fillna(sub[stat_col].values)\n",
    "    fills[mkt] = before - merged.loc[mask, \"actual_value\"].isna().sum()\n",
    "\n",
    "print(\"[backfill] filled:\", \", \".join(f\"{k}:{v}\" for k,v in fills.items() if v>0) or \"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e1dc4-0694-496a-9648-a11e707b3b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5d4fa-1605-4d0d-ab32-b92eb6ae48e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab54f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Compute gradeable outcomes ==============================================\n",
    "model_prob_col = \"model_prob\" if \"model_prob\" in merged.columns else None\n",
    "\n",
    "merged[\"pred_prob\"]  = np.nan\n",
    "merged[\"actual_bin\"] = np.nan\n",
    "\n",
    "# Binary markets\n",
    "mask_bin = merged[\"market_std\"].isin([\"anytime_td\",\"first_td\",\"last_td\"]) & (model_prob_col is not None)\n",
    "if mask_bin.any():\n",
    "    merged.loc[mask_bin, \"pred_prob\"]  = merged.loc[mask_bin, model_prob_col]\n",
    "    merged.loc[mask_bin, \"actual_bin\"] = merged.loc[mask_bin, \"actual_value\"].fillna(0).clip(0,1).astype(float)\n",
    "\n",
    "# O/U markets\n",
    "OU_MARKETS = {\n",
    "    \"pass_yds\",\"rush_yds\",\"recv_yds\",\"receptions\",\n",
    "    \"pass_completions\",\"pass_attempts\",\"rush_attempts\",\n",
    "    \"pass_tds\",\"pass_ints\"\n",
    "}\n",
    "mask_ou = (\n",
    "    merged[\"market_std\"].isin(OU_MARKETS) &\n",
    "    merged[\"line\"].notna() &\n",
    "    merged[\"actual_value\"].notna() &\n",
    "    merged[\"side\"].isin([\"over\",\"under\"])\n",
    ")\n",
    "\n",
    "side_over  = mask_ou & merged[\"side\"].eq(\"over\")\n",
    "side_under = mask_ou & merged[\"side\"].eq(\"under\")\n",
    "\n",
    "merged.loc[side_over,  \"actual_bin\"] = (merged.loc[side_over,  \"actual_value\"] >= merged.loc[side_over,  \"line\"]).astype(int)\n",
    "merged.loc[side_under, \"actual_bin\"] = (merged.loc[side_under, \"actual_value\"] <= merged.loc[side_under,  \"line\"]).astype(int)\n",
    "\n",
    "if model_prob_col:\n",
    "    merged.loc[mask_ou & merged[model_prob_col].notna(), \"pred_prob\"] = merged.loc[mask_ou, model_prob_col]\n",
    "\n",
    "gradeable = merged[\"pred_prob\"].notna() & merged[\"actual_bin\"].notna()\n",
    "graded = merged.loc[gradeable].copy()\n",
    "\n",
    "print(\"[gradeable] rows:\", len(graded))\n",
    "print(\"Markets graded:\\n\", graded[\"market_std\"].value_counts())\n",
    "graded.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1aad96a-9696-4e84-aed6-2c9192d2acd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 1) Force the backfill on *your* stats frame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m stats = ensure_player_key(stats)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# 2) Optional: confirm it really exists\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mplayer_key\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stats.columns \u001b[38;5;129;01mand\u001b[39;00m stats[\u001b[33m\"\u001b[39m\u001b[33mplayer_key\u001b[39m\u001b[33m\"\u001b[39m].notna().any(), \\\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m[assert] player_key was not created or is all NA\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd, unicodedata, re\n",
    "\n",
    "def std_name(s):\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s)).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return re.sub(r\"[^a-z]\", \"\", s.lower())\n",
    "\n",
    "def ensure_player_key(df: pd.DataFrame, name_cols=(\"player\", \"player_name\", \"name\"),\n",
    "                      team_cols=(\"recent_team\", \"team\", \"recent_team_abbr\", \"posteam\")) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"player_key\" in df.columns:\n",
    "        print(\"[ensure_player_key] already present\")\n",
    "        return df\n",
    "\n",
    "    # prefer stable IDs if available\n",
    "    for c in (\"player_id\", \"gsis_id\", \"nfl_id\", \"pfr_id\", \"pfr_player_id\"):\n",
    "        if c in df.columns:\n",
    "            df[\"player_key\"] = df[c].astype(str)\n",
    "            print(f\"[ensure_player_key] built from {c}\")\n",
    "            return df\n",
    "\n",
    "    name_col = next((c for c in name_cols if c in df.columns), None)\n",
    "    team_col = next((c for c in team_cols if c in df.columns), None)\n",
    "\n",
    "    if not name_col:\n",
    "        raise KeyError(\"[ensure_player_key] No name column found (looked for: \"\n",
    "                       + \", \".join(name_cols) + \")\")\n",
    "\n",
    "    df[\"name_std\"] = df[name_col].map(std_name)\n",
    "    if team_col:\n",
    "        df[\"player_key\"] = df[\"name_std\"] + \"_\" + df[team_col].astype(str).str.upper()\n",
    "        src = f\"{name_col}+{team_col}\"\n",
    "    else:\n",
    "        df[\"player_key\"] = df[\"name_std\"]\n",
    "        src = name_col\n",
    "\n",
    "    # sanity checks\n",
    "    nn = df[\"player_key\"].notna().sum()\n",
    "    uniq = df[\"player_key\"].nunique()\n",
    "    print(f\"[ensure_player_key] built from {src} → non-null: {nn:,}  unique: {uniq:,}\")\n",
    "\n",
    "    # show a few examples\n",
    "    print(df[[name_col] + ([team_col] if team_col else []) + [\"player_key\"]].head(8))\n",
    "    return df\n",
    "\n",
    "# 1) Force the backfill on *your* stats frame\n",
    "stats = ensure_player_key(stats)\n",
    "\n",
    "# 2) Optional: confirm it really exists\n",
    "assert \"player_key\" in stats.columns and stats[\"player_key\"].notna().any(), \\\n",
    "    \"[assert] player_key was not created or is all NA\"\n",
    "\n",
    "# 3) If you need a rename subset:\n",
    "rename_map = {\n",
    "    # examples — adjust to your script\n",
    "    \"rushing_yards\": \"rush_yds\",\n",
    "    \"receiving_yards\": \"rec_yds\",\n",
    "    \"passing_yards\": \"pass_yds\",\n",
    "    \"rushing_tds\": \"rush_tds\",\n",
    "    \"receiving_tds\": \"rec_tds\",\n",
    "    \"passing_tds\": \"pass_tds\",\n",
    "    \"interceptions\": \"pass_ints\",\n",
    "}\n",
    "have = [c for c in rename_map if c in stats.columns]\n",
    "use = stats.loc[:, [\"player_key\"] + ([\"name_std\"] if \"name_std\" in stats.columns else []) + have] \\\n",
    "           .rename(columns=rename_map, errors=\"ignore\")\n",
    "\n",
    "print(\"[use] cols →\", list(use.columns))\n",
    "\n",
    "# 4) Safe merge (replace `merged` with your props/dfp frame)\n",
    "#    Prefer player_key; fallback to name_std if needed.\n",
    "if \"player_key\" in merged.columns:\n",
    "    merged = merged.merge(use, on=\"player_key\", how=\"left\", validate=\"m:1\")\n",
    "elif \"name_std\" in merged.columns and \"name_std\" in use.columns:\n",
    "    merged = merged.merge(use.drop(columns=[\"player_key\"]), on=\"name_std\", how=\"left\", validate=\"m:1\")\n",
    "else:\n",
    "    raise KeyError(\"Neither player_key nor name_std present on both sides for merge\")\n",
    "\n",
    "print(\"[merge] rows:\", len(merged), \"  joined cols:\", [c for c in use.columns if c != \"player_key\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abbcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Scoring =================================================================\n",
    "def brier_score(p: np.ndarray, y: np.ndarray) -> float:\n",
    "    p = np.asarray(p, dtype=float); y = np.asarray(y, dtype=float)\n",
    "    return float(np.mean((p - y)**2))\n",
    "\n",
    "def log_loss(p: np.ndarray, y: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    p = np.clip(np.asarray(p, dtype=float), eps, 1-eps); y = np.asarray(y, dtype=float)\n",
    "    return float(-np.mean(y*np.log(p) + (1-y)*np.log(1-p)))\n",
    "\n",
    "def hit_rate(p: np.ndarray, y: np.ndarray, threshold: float = 0.5) -> float:\n",
    "    return float(np.mean(((p >= threshold).astype(int) == y.astype(int))))\n",
    "\n",
    "if len(graded) == 0:\n",
    "    raise SystemExit(\"No gradeable rows. Ensure model_prob, side, line, actual_value are present.\")\n",
    "\n",
    "overall = {\n",
    "    \"rows\": len(graded),\n",
    "    \"hit_rate@0.5\": hit_rate(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "    \"brier\": brier_score(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "    \"logloss\": log_loss(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "}\n",
    "overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d910867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Per-market & coverage ====================================================\n",
    "def summarize_by_market(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for mkt, g in df.groupby(\"market_std\"):\n",
    "        rows.append({\n",
    "            \"market_std\": mkt,\n",
    "            \"rows\": len(g),\n",
    "            \"hit_rate@0.5\": float((g[\"pred_prob\"]>=0.5).astype(int).eq(g[\"actual_bin\"]).mean()),\n",
    "            \"brier\": float(((g[\"pred_prob\"]-g[\"actual_bin\"])**2).mean()),\n",
    "            \"logloss\": float(-np.mean(g[\"actual_bin\"]*np.log(np.clip(g[\"pred_prob\"],1e-12,1-1e-12))+\n",
    "                                      (1-g[\"actual_bin\"])*np.log(np.clip(1-g[\"pred_prob\"],1e-12,1-1e-12)))),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values([\"brier\",\"logloss\",\"rows\"], ascending=[True,True,False])\n",
    "\n",
    "by_market = summarize_by_market(graded)\n",
    "\n",
    "cov = (\n",
    "    merged.assign(is_gradeable=merged.index.isin(graded.index))\n",
    "          .groupby(\"market_std\")\n",
    "          .agg(total_rows=(\"market_std\",\"size\"),\n",
    "               gradeable_rows=(\"is_gradeable\",\"sum\"))\n",
    "          .assign(coverage_pct=lambda d: d[\"gradeable_rows\"]/d[\"total_rows\"])\n",
    "          .reset_index()\n",
    ")\n",
    "\n",
    "by_market.head(10), cov.sort_values(\"coverage_pct\", ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Calibration ==============================================================\n",
    "def calibration_bins(df: pd.DataFrame, bins=10) -> pd.DataFrame:\n",
    "    cut = pd.cut(df[\"pred_prob\"], bins=bins, include_lowest=True)\n",
    "    return df.groupby(cut).agg(n=(\"actual_bin\",\"size\"),\n",
    "                               avg_pred=(\"pred_prob\",\"mean\"),\n",
    "                               emp_rate=(\"actual_bin\",\"mean\")).reset_index()\n",
    "\n",
    "calib = calibration_bins(graded, bins=10)\n",
    "plt.figure()\n",
    "plt.plot(calib[\"avg_pred\"], calib[\"emp_rate\"], marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted probability (bin avg)\"); plt.ylabel(\"Empirical win rate\")\n",
    "plt.title(f\"Calibration — Week {WEEK}\"); plt.grid(True); plt.show()\n",
    "\n",
    "calib.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Save outputs & quick summary ============================================\n",
    "graded.to_csv(EVAL_DIR/f\"grades_week{WEEK}.csv\", index=False)\n",
    "by_market.to_csv(EVAL_DIR/f\"grades_week{WEEK}_by_market.csv\", index=False)\n",
    "cov.to_csv(EVAL_DIR/f\"coverage_week{WEEK}.csv\", index=False)\n",
    "calib.to_csv(EVAL_DIR/f\"calibration_week{WEEK}.csv\", index=False)\n",
    "\n",
    "summary = (\n",
    "    f\"Week {WEEK} — graded {overall['rows']} props. \"\n",
    "    f\"Hit-rate@0.5={overall['hit_rate@0.5']:.1%}, \"\n",
    "    f\"Brier={overall['brier']:.3f}, LogLoss={overall['logloss']:.3f}. \"\n",
    ")\n",
    "best = by_market.sort_values(\"brier\").head(3).to_dict(\"records\")\n",
    "worst = by_market.sort_values(\"brier\").tail(3).to_dict(\"records\")\n",
    "summary += \"Best: \" + \", \".join(f\"{r['market_std']} (Brier {r['brier']:.3f}, n={r['rows']})\" for r in best) + \". \"\n",
    "summary += \"Needs work: \" + \", \".join(f\"{r['market_std']} (Brier {r['brier']:.3f}, n={r['rows']})\" for r in worst) + \".\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# shareables\n",
    "(EVAL_DIR/f\"qc_summary_week{WEEK}.json\").write_text(json.dumps({\"week\":WEEK, \"overall\":overall,\n",
    "                                                               \"best\":best, \"worst\":worst}, indent=2))\n",
    "(EVAL_DIR/f\"qc_summary_week{WEEK}.txt\").write_text(summary)\n",
    "\n",
    "print(f\"[write] {EVAL_DIR}/grades_week{WEEK}.csv\")\n",
    "print(f\"[write] {EVAL_DIR}/grades_week{WEEK}_by_market.csv\")\n",
    "print(f\"[write] {EVAL_DIR}/coverage_week{WEEK}.csv\")\n",
    "print(f\"[write] {EVAL_DIR}/calibration_week{WEEK}.csv\")\n",
    "print(f\"[write] {EVAL_DIR}/qc_summary_week{WEEK}.json / .txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418cc98-5724-4bd6-b7c4-f944c802e46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ea2d7-90f9-44ef-82e0-96f7a7297575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
