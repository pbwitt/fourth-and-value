{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e9bf67",
   "metadata": {},
   "source": [
    "\n",
    "# Fourth & Value — Game Predictions Walkthrough\n",
    "\n",
    "This notebook builds **game-level ML predictions** (spread & total) by rolling up **player weekly stats → team → game** and then training simple baseline models.\n",
    "\n",
    "**What you'll do here:**\n",
    "1. Load `stats_player_week_{SEASON}.parquet` (player-level weekly box scores).\n",
    "2. Roll up to **team/game totals**.\n",
    "3. Build **rolling features** per team (last N weeks).\n",
    "4. Construct **matchup features** (home vs away).\n",
    "5. Train **Ridge** models for **spread (point differential)** and **total (combined points)**.\n",
    "6. Evaluate on held-out weeks.\n",
    "7. (Optional) Compare model vs **market lines** from `data/odds/latest.csv`.\n",
    "\n",
    "> This is a **clear, testable scaffold**. Start with it as-is; then iterate: add better features (EPA, success rate, pace), injuries, weather/dome flags, and calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38575dcc",
   "metadata": {},
   "source": [
    "\n",
    "## Paths & Parameters\n",
    "\n",
    "Set your season/week here. This notebook expects your repo layout (as we've been using for props):\n",
    "- `data/weekly_player_stats_{SEASON}.parquet` ← downloaded from nflverse\n",
    "- `data/odds/latest.csv` ← from The Odds API (optional for later merge)\n",
    "- Outputs:\n",
    "  - `data/games/model_preds_week{WEEK}.csv` (predictions for the selected week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc61eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "SEASON = 2025\n",
    "WEEK   = 3\n",
    "\n",
    "PLAYER_PARQUET = Path(f\"data/weekly_player_stats_{SEASON}.parquet\")\n",
    "ODDS_CSV       = Path(\"data/odds/latest.csv\")\n",
    "OUT_DIR        = Path(\"data/games\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[conf] SEASON={SEASON} WEEK={WEEK}\")\n",
    "print(f\"[paths] player_stats={PLAYER_PARQUET.exists()} odds={ODDS_CSV.exists()} out_dir={OUT_DIR.as_posix()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4998433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not PLAYER_PARQUET.exists():\n",
    "    raise FileNotFoundError(f\"Missing {PLAYER_PARQUET}. Fetch via nflverse weekly release first.\")\n",
    "\n",
    "stats = pd.read_parquet(PLAYER_PARQUET)\n",
    "\n",
    "# Peek at columns so it's easy to adjust below if your schema differs.\n",
    "print(f\"[stats] shape={stats.shape}\")\n",
    "print(\"[stats] sample cols:\", list(stats.columns)[:25])\n",
    "stats.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cf7c0",
   "metadata": {},
   "source": [
    "\n",
    "## Roll up: Player → Team/Game\n",
    "\n",
    "We aggregate player stats up to **team** per **game**, keeping the **points** column as the target reference.\n",
    "If your parquet lacks any of these exact columns, tweak the mapping block below where noted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Column mapping (adjust here if needed) ----\n",
    "# Try common nflverse names; fall back if not present.\n",
    "def first_present(d, keys, default=np.nan):\n",
    "    for k in keys:\n",
    "        if k in d:\n",
    "            return d[k]\n",
    "    return default\n",
    "\n",
    "# Normalize a few expected columns\n",
    "# (You may tweak these if your parquet uses different names)\n",
    "colmap = {\n",
    "    \"team\":       \"team\",             # team abbreviation\n",
    "    \"opponent\":   \"opponent\",         # opponent team abbr\n",
    "    \"game_id\":    \"game_id\",\n",
    "    \"week\":       \"week\",\n",
    "    \"pass_yds\":   first_present(stats, [\"passing_yards\", \"pass_yards\", \"pass_yds\"], 0),\n",
    "    \"rush_yds\":   first_present(stats, [\"rushing_yards\", \"rush_yards\", \"rush_yds\"], 0),\n",
    "    \"ints\":       first_present(stats, [\"interceptions\", \"int\", \"interceptions_thrown\"], 0),\n",
    "    \"fumbles_lost\": first_present(stats, [\"fumbles_lost\", \"fumbles_lost_team\"], 0),\n",
    "    \"sacks\":      first_present(stats, [\"sacks\", \"sacked\", \"sacks_taken\"], 0),\n",
    "    \"points\":     first_present(stats, [\"points\", \"team_points\", \"pts\"], np.nan),\n",
    "}\n",
    "\n",
    "# Build a lightweight frame with mapped columns\n",
    "mini = pd.DataFrame({\n",
    "    \"game_id\":   stats[\"game_id\"],\n",
    "    \"week\":      stats[\"week\"],\n",
    "    \"team\":      stats[\"team\"],\n",
    "    \"opponent\":  stats.get(\"opponent\", stats.get(\"opp\", np.nan)),\n",
    "    \"pass_yds\":  colmap[\"pass_yds\"],\n",
    "    \"rush_yds\":  colmap[\"rush_yds\"],\n",
    "    \"ints\":      colmap[\"ints\"],\n",
    "    \"fumbles_lost\": colmap[\"fumbles_lost\"],\n",
    "    \"sacks\":     colmap[\"sacks\"],\n",
    "    \"points\":    colmap[\"points\"],\n",
    "})\n",
    "\n",
    "# Aggregate to team per game\n",
    "team_games = (\n",
    "    mini.groupby([\"game_id\", \"week\", \"team\"], dropna=False)\n",
    "        .agg(pass_yds=(\"pass_yds\",\"sum\"),\n",
    "             rush_yds=(\"rush_yds\",\"sum\"),\n",
    "             turnovers=(\"ints\",\"sum\"),\n",
    "             fumbles_lost=(\"fumbles_lost\",\"sum\"),\n",
    "             sacks=(\"sacks\",\"sum\"),\n",
    "             points=(\"points\",\"max\"))  # team points should be same for all players\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "print(\"[team_games] shape:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0befe40d",
   "metadata": {},
   "source": [
    "\n",
    "## Rolling Features per Team\n",
    "\n",
    "We compute simple **rolling means** over the last `window` weeks to stabilize noisy weekly stats.\n",
    "You can switch to **exponential moving averages** or **weighted** windows easily later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af687374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_rolling_features(df: pd.DataFrame, window: int = 3) -> pd.DataFrame:\n",
    "    # Ensure proper sorting for rolling\n",
    "    df = df.sort_values([\"team\", \"week\"])\n",
    "    # Rolling means per team\n",
    "    grouped = df.groupby(\"team\", group_keys=False).apply(\n",
    "        lambda g: g.assign(\n",
    "            pass_yds_r = g[\"pass_yds\"].rolling(window, min_periods=1).mean(),\n",
    "            rush_yds_r = g[\"rush_yds\"].rolling(window, min_periods=1).mean(),\n",
    "            to_r       = g[\"turnovers\"].rolling(window, min_periods=1).mean(),\n",
    "            sacks_r    = g[\"sacks\"].rolling(window, min_periods=1).mean(),\n",
    "            pts_r      = g[\"points\"].rolling(window, min_periods=1).mean(),\n",
    "        )\n",
    "    )\n",
    "    return grouped\n",
    "\n",
    "team_feats = add_rolling_features(team_games, window=3)\n",
    "print(\"[team_feats] shape:\", team_feats.shape)\n",
    "team_feats.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45268920",
   "metadata": {},
   "source": [
    "\n",
    "## Matchup Rows (Home vs Away)\n",
    "\n",
    "We build **one row per game**, with **feature differences** for spread and **sums** for totals.\n",
    "We infer home/away from the team-level frame. If your dataset doesn’t carry a clear home/away flag,\n",
    "we’ll detect it from the **team vs opp** relationship per game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We need both teams per game with a clear home/away. If your dataset doesn't carry home/away flags,\n",
    "# we'll pair teams within game_id arbitrarily and then label the first as 'home' for feature construction.\n",
    "# Later you can replace with actual home/away flags from schedules if desired.\n",
    "\n",
    "# Build all team pairs within a game (two rows → one row)\n",
    "pairs = (team_feats.merge(team_feats, on=[\"game_id\",\"week\"], suffixes=(\"_home\",\"_away\"))\n",
    "                   .query(\"team_home != team_away\"))\n",
    "\n",
    "# Keep exactly one pairing per game: sort team codes to choose one canonical order\n",
    "pairs[\"canon\"] = pairs.apply(lambda r: \"|\".join(sorted([r[\"team_home\"], r[\"team_away\"]])), axis=1)\n",
    "pairs = pairs.sort_values([\"game_id\",\"canon\",\"team_home\"]).drop_duplicates([\"game_id\",\"canon\"])\n",
    "\n",
    "# Feature diffs (for spread) and sums (for totals)\n",
    "pairs[\"yds_diff_r\"] = (pairs[\"pass_yds_r_home\"] + pairs[\"rush_yds_r_home\"]\n",
    "                       - (pairs[\"pass_yds_r_away\"] + pairs[\"rush_yds_r_away\"]))\n",
    "pairs[\"to_diff_r\"]  = pairs[\"to_r_home\"] - pairs[\"to_r_away\"]\n",
    "pairs[\"sack_diff_r\"]= pairs[\"sacks_r_home\"] - pairs[\"sacks_r_away\"]\n",
    "\n",
    "# Targets from points\n",
    "pairs[\"spread_actual\"] = pairs[\"points_home\"] - pairs[\"points_away\"]\n",
    "pairs[\"total_actual\"]  = pairs[\"points_home\"] + pairs[\"points_away\"]\n",
    "\n",
    "matchups = pairs[[\"game_id\",\"week\",\n",
    "                  \"team_home\",\"team_away\",\n",
    "                  \"yds_diff_r\",\"to_diff_r\",\"sack_diff_r\",\n",
    "                  \"spread_actual\",\"total_actual\"]].copy()\n",
    "\n",
    "print(\"[matchups] shape:\", matchups.shape)\n",
    "matchups.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff1cdf",
   "metadata": {},
   "source": [
    "\n",
    "## Train & Predict (Ridge)\n",
    "\n",
    "Two independent regressions:\n",
    "- **Spread** target = `points_home - points_away`\n",
    "- **Total** target = `points_home + points_away`\n",
    "\n",
    "We keep the baseline small (Ridge) to make debugging easy, then you can upgrade (e.g., GradientBoosting, XGBoost).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train = all weeks < WEEK; Test = WEEK\n",
    "train = matchups[matchups[\"week\"] < WEEK].copy()\n",
    "test  = matchups[matchups[\"week\"] == WEEK].copy()\n",
    "\n",
    "feature_cols = [\"yds_diff_r\",\"to_diff_r\",\"sack_diff_r\"]\n",
    "\n",
    "print(f\"[split] train={train.shape} test={test.shape}\")\n",
    "train[[\"week\"] + feature_cols + [\"spread_actual\",\"total_actual\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbe875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_ridge(train_df, target, features):\n",
    "    X = train_df[features].values\n",
    "    y = train_df[target].values\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "spread_model = fit_ridge(train, \"spread_actual\", feature_cols)\n",
    "total_model  = fit_ridge(train, \"total_actual\",  feature_cols)\n",
    "\n",
    "test = test.copy()\n",
    "test[\"spread_pred\"] = spread_model.predict(test[feature_cols].values)\n",
    "test[\"total_pred\"]  = total_model.predict(test[feature_cols].values)\n",
    "\n",
    "test[[\"game_id\",\"team_home\",\"team_away\",\"spread_pred\",\"total_pred\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fda62",
   "metadata": {},
   "source": [
    "\n",
    "## Quick Evaluation\n",
    "\n",
    "Compute MAE for both targets on the test week (or a validation split). For proper backtests,\n",
    "loop weeks and gather errors across folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde13807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae(a, b): \n",
    "    return float(np.abs(a - b).mean()) if len(a) else np.nan\n",
    "\n",
    "mae_spread = mae(test[\"spread_pred\"], test[\"spread_actual\"]) if \"spread_actual\" in test else np.nan\n",
    "mae_total  = mae(test[\"total_pred\"],  test[\"total_actual\"])  if \"total_actual\"  in test else np.nan\n",
    "\n",
    "print(f\"[eval] MAE spread (week={WEEK}): {mae_spread:.3f}\")\n",
    "print(f\"[eval] MAE total  (week={WEEK}): {mae_total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9004d8",
   "metadata": {},
   "source": [
    "\n",
    "## Export Predictions\n",
    "\n",
    "Write per-game predictions for the chosen week:\n",
    "`data/games/model_preds_week{WEEK}.csv`\n",
    "\n",
    "This mirrors your props flow so you can later add a **site page** and **edges vs market**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40016f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = test[[\"game_id\",\"team_home\",\"team_away\",\"spread_pred\",\"total_pred\"]].rename(\n",
    "    columns={\"spread_pred\":\"model_spread\",\"total_pred\":\"model_total\"}\n",
    ").copy()\n",
    "\n",
    "out_path = OUT_DIR / f\"model_preds_week{WEEK}.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "print(f\"[write] {out_path.as_posix()} ({out.shape[0]} rows)\")\n",
    "out.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e084d7",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "\n",
    "- Add richer features (EPA/play, success rate, early-downs rates, pace).\n",
    "- Injury/QB adjustments (at minimum a QB availability flag or ELO-style rating shift).\n",
    "- Weather/dome flags.\n",
    "- Calibration & book comparisons:\n",
    "  - Convert spread to **win probability** with a logistic link.\n",
    "  - Compare to market moneylines and compute **edge**.\n",
    "- Integrate into Makefile (`make game_preds`) once satisfied with outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTIONAL: Merge with market lines to compute edges later.\n",
    "# This block is a stub; you'll likely have to map game keys with your odds format.\n",
    "if ODDS_CSV.exists():\n",
    "    odds = pd.read_csv(ODDS_CSV)\n",
    "    print(\"[odds] shape:\", odds.shape)\n",
    "    display(odds.head())\n",
    "else:\n",
    "    print(\"[odds] not found; skip for now.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
