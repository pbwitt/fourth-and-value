{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09667af6",
   "metadata": {},
   "source": [
    "# Week 2 â€” Build Actuals âžœ Grade Model Performance (All-in-One) ðŸš€\n",
    "\n",
    "This notebook does **everything** for Week 2 in one run:\n",
    "\n",
    "1. Load Week 2 props (`data/props/props_with_model_week2.csv`)\n",
    "2. Load weekly player stats (`data/weekly_player_stats_2025.parquet` or `.csv.gz`)\n",
    "3. Build actuals â†’ `data/actuals/week2.csv`\n",
    "4. Grade model vs actuals â†’ write `data/eval/grades_week2.csv` and `data/eval/market_perf_week2.csv`\n",
    "5. Show best markets and print **tweet-ready** summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0aca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BASE] /Users/pwitt/fourth-and-value\n",
      "[check] props: /Users/pwitt/fourth-and-value/data/props/props_with_model_week2.csv True\n",
      "[check] stats parquet: /Users/pwitt/fourth-and-value/data/weekly_player_stats_2025.parquet True\n",
      "[check] stats csv.gz : /Users/pwitt/fourth-and-value/data/weekly_player_stats_2025.csv.gz False\n",
      "[props] shape: (2673, 24)\n",
      "[stats] shape (raw): (2041, 114)\n",
      "[stats] after season/week filter: (970, 114)\n",
      "[join] props.player_key  <->  stats.player_id\n",
      "[stats] using columns: ['attempts', 'completions', 'passing_tds', 'passing_yards', 'player_id', 'receiving_tds', 'receiving_yards', 'receptions', 'rushing_tds', 'rushing_yards']\n",
      "[merge] merged rows: 2673\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['side'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 140\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mplayer_key\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dfm.columns \u001b[38;5;129;01mand\u001b[39;00m left_key \u001b[38;5;129;01min\u001b[39;00m dfm.columns:\n\u001b[32m    139\u001b[39m     dfm[\u001b[33m\"\u001b[39m\u001b[33mplayer_key\u001b[39m\u001b[33m\"\u001b[39m] = dfm[left_key]\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m actuals = dfm[out_cols].copy()\n\u001b[32m    141\u001b[39m actuals = actuals[actuals[\u001b[33m\"\u001b[39m\u001b[33mactual_value\u001b[39m\u001b[33m\"\u001b[39m].notna()].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    142\u001b[39m actuals.to_csv(actuals_out, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns._get_indexer_strict(key, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_if_missing(keyarr, indexer, axis_name)\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['side'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Params ---\n",
    "WEEK = 2\n",
    "SEASON = 2025\n",
    "\n",
    "# --- Repo base autodetect (folder with Makefile + data/) ---\n",
    "BASE = Path.cwd()\n",
    "for p in [BASE] + list(BASE.parents):\n",
    "    if (p/\"Makefile\").exists() and (p/\"data\").exists():\n",
    "        BASE = p\n",
    "        break\n",
    "print(\"[BASE]\", BASE)\n",
    "\n",
    "props_path = BASE / f\"data/props/props_with_model_week{WEEK}.csv\"\n",
    "stats_parq = BASE / \"data/weekly_player_stats_2025.parquet\"\n",
    "stats_csvz = BASE / \"data/weekly_player_stats_2025.csv.gz\"\n",
    "actuals_out = BASE / f\"data/actuals/week{WEEK}.csv\"\n",
    "grades_out  = BASE / f\"data/eval/grades_week{WEEK}.csv\"\n",
    "market_out  = BASE / f\"data/eval/market_perf_week{WEEK}.csv\"\n",
    "\n",
    "print(\"[check] props:\", props_path, props_path.exists())\n",
    "print(\"[check] stats parquet:\", stats_parq, stats_parq.exists())\n",
    "print(\"[check] stats csv.gz :\", stats_csvz, stats_csvz.exists())\n",
    "\n",
    "if not props_path.exists():\n",
    "    raise SystemExit(f\"[ERR] missing props file: {props_path}\\nRun your monday build first.\")\n",
    "if not (stats_parq.exists() or stats_csvz.exists()):\n",
    "    raise SystemExit(\"[ERR] missing weekly player stats. Fetch parquet (preferred) or csv.gz before running.\")\n",
    "\n",
    "# --- Load props ---\n",
    "dfp = pd.read_csv(props_path)\n",
    "print(\"[props] shape:\", dfp.shape)\n",
    "\n",
    "# --- Load stats (prefer parquet) ---\n",
    "if stats_parq.exists():\n",
    "    dfs = pd.read_parquet(stats_parq)\n",
    "else:\n",
    "    dfs = pd.read_csv(stats_csvz)\n",
    "\n",
    "print(\"[stats] shape (raw):\", dfs.shape)\n",
    "if {\"season\",\"week\"}.issubset(dfs.columns):\n",
    "    dfs = dfs[(dfs[\"season\"]==SEASON) & (dfs[\"week\"]==WEEK)]\n",
    "    print(\"[stats] after season/week filter:\", dfs.shape)\n",
    "else:\n",
    "    print(\"[warn] stats missing season/week columns; proceeding without filter\")\n",
    "\n",
    "# --- Join keys ---\n",
    "left_key = None; right_key = None\n",
    "if \"player_key\" in dfp.columns and \"player_id\" in dfs.columns:\n",
    "    left_key, right_key = \"player_key\", \"player_id\"\n",
    "else:\n",
    "    # name fallback (less reliable)\n",
    "    left_key  = next((c for c in [\"player\",\"name\",\"player_name\"] if c in dfp.columns), None)\n",
    "    right_key = next((c for c in [\"player_name\",\"player\",\"name\",\"full_name\"] if c in dfs.columns), None)\n",
    "if not left_key or not right_key:\n",
    "    raise SystemExit(\"[ERR] no compatible join keys (need player_keyâ†”player_id or nameâ†”name)\")\n",
    "\n",
    "print(f\"[join] props.{left_key}  <->  stats.{right_key}\")\n",
    "\n",
    "# --- Keep minimal stats columns ---\n",
    "need_stat_cols = {\n",
    "    right_key,\n",
    "    \"rushing_yards\",\"receiving_yards\",\"passing_yards\",\n",
    "    \"receptions\",\"rushing_attempts\",\"completions\",\"attempts\",\n",
    "    \"passing_tds\",\"interceptions\",\"rushing_tds\",\"receiving_tds\",\n",
    "}\n",
    "dfs_small = dfs[[c for c in need_stat_cols if c in dfs.columns]].copy()\n",
    "print(\"[stats] using columns:\", sorted(dfs_small.columns))\n",
    "\n",
    "# --- Merge props to stats (left join keeps all props) ---\n",
    "dfm = dfp.merge(dfs_small, left_on=left_key, right_on=right_key, how=\"left\", suffixes=(\"\",\"_stat\"))\n",
    "print(\"[merge] merged rows:\", len(dfm))\n",
    "\n",
    "# --- Market mapping & actuals computation ---\n",
    "MAP = {\n",
    "    # yards\n",
    "    \"rush_yds\":\"rushing_yards\",\"rushing_yds\":\"rushing_yards\",\"rush_yards\":\"rushing_yards\",\"rushing_yards\":\"rushing_yards\",\n",
    "    \"recv_yds\":\"receiving_yards\",\"reception_yds\":\"receiving_yards\",\"receiving_yards\":\"receiving_yards\",\n",
    "    \"pass_yds\":\"passing_yards\",\"passing_yards\":\"passing_yards\",\n",
    "    # counts\n",
    "    \"rec\":\"receptions\",\"receptions\":\"receptions\",\n",
    "    \"rush_att\":\"rushing_attempts\",\"rush_attempts\":\"rushing_attempts\",\"rushing_attempts\":\"rushing_attempts\",\"carries\":\"rushing_attempts\",\n",
    "    \"pass_cmp\":\"completions\",\"pass_completions\":\"completions\",\"completions\":\"completions\",\n",
    "    \"pass_att\":\"attempts\",\"pass_attempts\":\"attempts\",\"attempts\":\"attempts\",\n",
    "    \"pass_tds\":\"passing_tds\",\"passing_tds\":\"passing_tds\",\n",
    "    \"pass_ints\":\"interceptions\",\"pass_interceptions\":\"interceptions\",\"interceptions\":\"interceptions\",\n",
    "}\n",
    "YESNO = {\"anytime_td\"}\n",
    "UNSUPPORTED_PREFIX = (\"first_td\",\"first_team_td\",\"rush_longest\",\"reception_longest\",\"longest_reception\",\"longest_rush\")\n",
    "\n",
    "def norm_market(m):\n",
    "    if pd.isna(m): return \"\"\n",
    "    return str(m).strip().lower().replace(\" \",\"_\").replace(\"-\",\"_\")\n",
    "\n",
    "def actual_value(row):\n",
    "    m = norm_market(row.get(\"market_std\",\"\"))\n",
    "    if m.startswith(UNSUPPORTED_PREFIX): return np.nan\n",
    "    if m in YESNO:\n",
    "        td = (row.get(\"rushing_tds\",0) or 0) + (row.get(\"receiving_tds\",0) or 0)\n",
    "        return float(td)\n",
    "    statcol = MAP.get(m, None)\n",
    "    if statcol is None: return np.nan\n",
    "    v = row.get(statcol, np.nan)\n",
    "    try: return float(v)\n",
    "    except Exception: return np.nan\n",
    "\n",
    "def decide_result(side, actual, point):\n",
    "    if pd.isna(actual): return np.nan\n",
    "    s = (str(side) if side is not None else \"\").strip().lower()\n",
    "    if s in (\"yes\",\"no\"):\n",
    "        yes = actual > 0\n",
    "        return 1 if ((s==\"yes\" and yes) or (s==\"no\" and not yes)) else 0\n",
    "    p = None\n",
    "    try:\n",
    "        p = float(point) if point not in (None,\"\") else None\n",
    "    except Exception:\n",
    "        p = None\n",
    "    if p is None: return np.nan\n",
    "    if s==\"over\":  return 1 if actual >= p else 0\n",
    "    if s==\"under\": return 1 if actual <= p else 0\n",
    "    return np.nan\n",
    "\n",
    "have_point = \"point_key\" in dfm.columns\n",
    "dfm[\"actual_value\"] = dfm.apply(actual_value, axis=1)\n",
    "dfm[\"result\"] = [\n",
    "    decide_result(row.get(\"side\"), row.get(\"actual_value\"), row.get(\"point_key\") if have_point else None)\n",
    "    for _, row in dfm.iterrows()\n",
    "]\n",
    "\n",
    "# --- Write actuals ---\n",
    "actuals_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_cols = [\"player_key\",\"market_std\",\"side\",\"actual_value\",\"result\"]\n",
    "if have_point: out_cols.insert(2,\"point_key\")\n",
    "# fill player_key if missing via join key\n",
    "if \"player_key\" not in dfm.columns and left_key in dfm.columns:\n",
    "    dfm[\"player_key\"] = dfm[left_key]\n",
    "actuals = dfm[out_cols].copy()\n",
    "actuals = actuals[actuals[\"actual_value\"].notna()].reset_index(drop=True)\n",
    "actuals.to_csv(actuals_out, index=False)\n",
    "print(f\"[write] actuals -> {actuals_out}  rows={len(actuals)}\")\n",
    "\n",
    "# === Grading section ===\n",
    "def amer_to_prob(oa):\n",
    "    if pd.isna(oa): return np.nan\n",
    "    oa = float(oa)\n",
    "    return (-oa)/((-oa)+100.0) if oa < 0 else 100.0/(oa+100.0)\n",
    "\n",
    "def amer_to_decimal(oa):\n",
    "    if pd.isna(oa): return np.nan\n",
    "    oa = float(oa)\n",
    "    return (1 + 100.0/(-oa)) if oa < 0 else (1 + oa/100.0)\n",
    "\n",
    "# Re-merge props + freshly written actuals to be safe\n",
    "dfa = actuals  # already aligned\n",
    "merged = dfp.merge(dfa, on=[c for c in [\"player_key\",\"market_std\",\"side\"] + ([\"point_key\"] if have_point else []) if c in dfp.columns and c in dfa.columns],\n",
    "                   how=\"left\", suffixes=(\"\",\"_act\"))\n",
    "print(\"[grade] merged rows:\", len(merged), \" matched results:\", merged[\"result\"].notna().sum())\n",
    "\n",
    "# Column mapping for metrics\n",
    "c_side  = next((c for c in [\"side\",\"bet_side\",\"ou_side\",\"yes_no_side\"] if c in merged.columns), \"side\")\n",
    "c_pmod  = next((c for c in [\"model_prob\",\"model_p\",\"p_model\",\"pred_prob\"] if c in merged.columns), None)\n",
    "c_pbook = next((c for c in [\"mkt_prob\",\"consensus_prob\",\"book_implied_prob\"] if c in merged.columns), None)\n",
    "c_odds  = next((c for c in [\"odds_american\",\"mkt_odds_american\",\"american_odds\",\"price\"] if c in merged.columns), None)\n",
    "if c_pmod is None: raise SystemExit(\"Missing model probability column (e.g., model_prob).\")\n",
    "\n",
    "# Coerce\n",
    "merged[c_pmod]  = pd.to_numeric(merged[c_pmod], errors=\"coerce\").clip(0,1)\n",
    "if c_pbook: merged[c_pbook] = pd.to_numeric(merged[c_pbook], errors=\"coerce\").clip(0,1)\n",
    "if c_odds:  merged[c_odds]  = pd.to_numeric(merged[c_odds], errors=\"coerce\")\n",
    "\n",
    "# Fill market prob from odds if needed\n",
    "if c_pbook and merged[c_pbook].isna().any():\n",
    "    merged[c_pbook] = merged[c_pbook].fillna(merged[c_odds].apply(amer_to_prob) if c_odds else np.nan)\n",
    "\n",
    "# Effective probs by side\n",
    "side = merged[c_side].astype(str).str.lower()\n",
    "yes_like = side.isin([\"over\",\"yes\"])\n",
    "p_model_eff = merged[c_pmod].where(yes_like, 1.0 - merged[c_pmod])\n",
    "p_mkt_eff   = (merged[c_pbook].where(yes_like, 1.0 - merged[c_pbook])) if c_pbook else np.nan\n",
    "\n",
    "# Metrics\n",
    "eps = 1e-9\n",
    "p_safe = merged[c_pmod].clip(eps, 1-eps)\n",
    "merged[\"brier\"] = (merged[c_pmod] - merged[\"result\"])**2\n",
    "merged[\"logloss\"] = -(merged[\"result\"]*np.log(p_safe) + (1-merged[\"result\"])*np.log(1-p_safe))\n",
    "\n",
    "# ROI via odds if present else from mkt_prob\n",
    "if c_odds:\n",
    "    merged[\"decimal_odds\"] = merged[c_odds].apply(amer_to_decimal)\n",
    "else:\n",
    "    merged[\"decimal_odds\"] = np.nan\n",
    "no_price = merged[\"decimal_odds\"].isna()\n",
    "if no_price.any() and c_pbook:\n",
    "    merged.loc[no_price & merged[c_pbook].gt(0), \"decimal_odds\"] = 1.0 / merged.loc[no_price, c_pbook]\n",
    "merged[\"ev_realized_per_$1\"] = merged[\"result\"] * (merged[\"decimal_odds\"] - 1.0) - (1 - merged[\"result\"]) * 1.0\n",
    "\n",
    "# Edge sign capture\n",
    "merged[\"edge_dir\"] = (p_model_eff - p_mkt_eff) if c_pbook else np.nan\n",
    "merged[\"edge_hit\"] = (((merged[\"edge_dir\"] > 0) & (merged[\"result\"] == 1)) | ((merged[\"edge_dir\"] < 0) & (merged[\"result\"] == 0))).astype(\"float\")\n",
    "\n",
    "# Overall\n",
    "try:\n",
    "    corr = float(pd.Series(merged[c_pmod]).corr(pd.Series(merged[\"result\"])))\n",
    "except Exception:\n",
    "    corr = np.nan\n",
    "\n",
    "print(f\"[overall] rows={len(merged)}  hit={merged['result'].mean():.3f}  \"\n",
    "      f\"Brier={merged['brier'].mean():.4f}  LogLoss={merged['logloss'].mean():.4f}  \"\n",
    "      f\"ROI/1={merged['ev_realized_per_$1'].mean():.4f}  corr(p,y)={corr:.3f}\")\n",
    "\n",
    "# Write grades\n",
    "keep = [\"player_key\",\"market_std\",\"side\",\"point_key\"] if \"point_key\" in merged.columns else [\"player_key\",\"market_std\",\"side\"]\n",
    "keep += [c for c in [c_pmod, c_pbook, c_odds, \"decimal_odds\", \"result\", \"brier\", \"logloss\", \"edge_dir\", \"edge_hit\", \"ev_realized_per_$1\"] if c in merged.columns]\n",
    "grades = merged[keep].copy()\n",
    "grades_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "grades.to_csv(grades_out, index=False)\n",
    "print(\"[write] grades ->\", grades_out)\n",
    "\n",
    "# Per-market performance (dict-based named aggregation to allow '$' in col name)\n",
    "def safemean(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.dropna().mean()\n",
    "\n",
    "perf = grades.groupby(\"market_std\", dropna=False).agg({\n",
    "    \"n\": (\"result\",\"count\"),\n",
    "    \"hit\": (\"result\",\"mean\"),\n",
    "    \"brier\": (\"brier\", safemean),\n",
    "    \"logloss\": (\"logloss\", safemean),\n",
    "    \"edge_hit_rate\": (\"edge_hit\", safemean),\n",
    "    \"avg_edge_dir\": (\"edge_dir\", safemean),\n",
    "    \"roi_per_$1\": (\"ev_realized_per_$1\", safemean),\n",
    "}).reset_index()\n",
    "\n",
    "perf.to_csv(market_out, index=False)\n",
    "print(\"[write] per-market ->\", market_out)\n",
    "\n",
    "# Rankers\n",
    "top_by_roi   = perf.sort_values([\"roi_per_$1\",\"n\"], ascending=[False, False]).head(12)\n",
    "top_by_brier = perf.sort_values([\"brier\",\"n\"], ascending=[True, False]).head(12)\n",
    "\n",
    "display(perf.sort_values(\"roi_per_$1\", ascending=False).head(20))\n",
    "display(top_by_roi)\n",
    "display(top_by_brier)\n",
    "\n",
    "# Tweet-ready summary\n",
    "overall = {\n",
    "    \"n\": int(grades[\"result\"].count()),\n",
    "    \"hit\": float(grades[\"result\"].mean()),\n",
    "    \"brier\": float(pd.to_numeric(grades[\"brier\"], errors=\"coerce\").mean()),\n",
    "    \"logloss\": float(pd.to_numeric(grades[\"logloss\"], errors=\"coerce\").mean()),\n",
    "    \"roi\": float(pd.to_numeric(grades[\"ev_realized_per_$1\"], errors=\"coerce\").mean()),\n",
    "}\n",
    "print(\"\\n--- Tweet-ready ---\")\n",
    "print(f\"Wk2 model vs actuals â€” n={overall['n']}, hit={overall['hit']:.3f}, Brier={overall['brier']:.3f}, LogLoss={overall['logloss']:.3f}, ROI/1={overall['roi']:.3f}.\")\n",
    "\n",
    "pf = perf[perf[\"n\"] >= 25].sort_values(\"roi_per_$1\", ascending=False).head(5)  # min sample to avoid tiny sets\n",
    "for _, r in pf.iterrows():\n",
    "    print(f\"{r['market_std']}: n={int(r['n'])}, hit={r['hit']:.3f}, ROI/1={r['roi_per_$1']:.3f}, Brier={r['brier']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ad96e",
   "metadata": {},
   "source": [
    "### (Optional) Quick ROI chart by market\n",
    "\n",
    "This uses matplotlib (no styles/colors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cc0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'perf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pf = perf.sort_values(\u001b[33m\"\u001b[39m\u001b[33mroi_per_$1\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m12\u001b[39m)\n\u001b[32m      4\u001b[39m plt.figure()\n\u001b[32m      5\u001b[39m plt.bar(pf[\u001b[33m\"\u001b[39m\u001b[33mmarket_std\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m), pf[\u001b[33m\"\u001b[39m\u001b[33mroi_per_$1\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'perf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pf = perf.sort_values(\"roi_per_$1\", ascending=False).head(12)\n",
    "plt.figure()\n",
    "plt.bar(pf[\"market_std\"].astype(str), pf[\"roi_per_$1\"])\n",
    "plt.title(\"Week 2 â€” ROI per $1 by Market (Top 12)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"ROI per $1\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab757b-894a-44f7-8f2e-f0d5ad257a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
