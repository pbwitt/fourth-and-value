{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "947bd6bc-b10b-48a7-950a-b56a2f8c6d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[import] using /Users/pwitt/fourth-and-value/scripts/common_markets.py\n",
      "[dfp] cols present → ['line', 'market_std', 'model_prob', 'name_std', 'side']\n",
      "[merge] rows: 2,673\n",
      "[coverage] with actual_side: 537\n",
      "[coverage] pushes: 0\n",
      "[debug] stage counts\n",
      "  total rows         : 2673\n",
      "  has line           : 1438\n",
      "  has actual_value   : 537\n",
      "  OU gradeable rows  : 0\n",
      "  anytime gradeable  : 537\n",
      "  side present       : 2673\n",
      "  mask_grade rows    : 537\n",
      "[hit-rate] 0.000 on 537 graded rows\n",
      "[brier] 0.049   [logloss] 0.250   (n=537)\n",
      "[write] /Users/pwitt/fourth-and-value/data/eval/grades_week2.csv\n",
      "[write] /Users/pwitt/fourth-and-value/data/eval/grades_week2_by_market.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== WEEK 2 GRADING — STABLE / DEFENSIVE ====\n",
    "from pathlib import Path\n",
    "import sys, importlib\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "\n",
    "# --- 0) Make scripts/ importable (so we reuse your normalizers) ---\n",
    "ROOT = None\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if (p/\"scripts/common_markets.py\").exists():\n",
    "        ROOT = p; break\n",
    "if ROOT is None:\n",
    "    raise FileNotFoundError(\"Couldn't find scripts/common_markets.py walking up from CWD.\")\n",
    "sys.path.insert(0, str(ROOT/\"scripts\"))\n",
    "cm = importlib.import_module(\"common_markets\")\n",
    "standardize_input = cm.standardize_input\n",
    "std_player_name   = getattr(cm, \"std_player_name\", lambda s: s)\n",
    "\n",
    "print(\"[import] using\", ROOT/\"scripts/common_markets.py\")\n",
    "\n",
    "# --- 1) Load + normalize predictions (already pipeline output but columns vary) ---\n",
    "dfp_raw = pd.read_csv(ROOT/\"data/props/props_with_model_week2.csv\")\n",
    "\n",
    "dfp = standardize_input(\n",
    "    dfp_raw,\n",
    "    market_col_candidates=(\"market_std\",\"market\",\"market_name\",\"market_key\",\"key\",\"market_slug\"),\n",
    "    name_col_candidates=(\"side\",\"name\",\"selection\",\"bet_name\",\"over_under\",\"bet_side\",\"bet\"),\n",
    "    point_col_candidates=(\"line\",\"point\",\"odds_point\",\"bet_line\",\"points\",\"handicap\",\"total\"),\n",
    "    player_col_candidates=(\"name_std\",\"player\",\"player_name\",\"athlete\",\"athlete_name\",\"name_player\"),\n",
    ").rename(columns={\"point\":\"line\",\"name\":\"side\"})\n",
    "\n",
    "# Normalize types now (avoid dtype mismatch later)\n",
    "dfp[\"line\"] = pd.to_numeric(dfp[\"line\"], errors=\"coerce\")\n",
    "if \"model_prob\" in dfp.columns:\n",
    "    dfp[\"model_prob\"] = pd.to_numeric(dfp[\"model_prob\"], errors=\"coerce\")\n",
    "# Force side to object dtype explicitly and standardize Over/Under/Yes/No\n",
    "_side_map = {\"o\":\"Over\",\"over\":\"Over\",\"ovr\":\"Over\",\"+\":\"Over\",\n",
    "             \"u\":\"Under\",\"under\":\"Under\",\"und\":\"Under\",\"-\":\"Under\",\n",
    "             \"yes\":\"Yes\",\"no\":\"No\"}\n",
    "dfp[\"side\"] = (dfp[\"side\"].astype(\"string\").str.strip().str.lower()\n",
    "               .map(_side_map).astype(\"object\"))\n",
    "\n",
    "need_cols = {\"market_std\",\"name_std\",\"line\",\"side\"}\n",
    "print(\"[dfp] cols present →\", sorted(set(dfp.columns) & (need_cols | {\"model_prob\"})))\n",
    "\n",
    "# --- 2) Load Week 2 actuals (nflverse weekly) ---\n",
    "dfs = pd.read_parquet(ROOT/\"data/weekly_player_stats_2025.parquet\")\n",
    "dfs = dfs.query(\"season == 2025 and week == 2\").copy()\n",
    "name_col = next((c for c in [\"player_name\",\"player\",\"name\"] if c in dfs.columns), None)\n",
    "if not name_col:\n",
    "    raise RuntimeError(\"[dfs] couldn't find a player name column\")\n",
    "\n",
    "dfs[\"name_std\"] = dfs[name_col].map(std_player_name)\n",
    "\n",
    "# --- 3) Map canonical markets -> nflverse columns (defensive) ---\n",
    "def pick(df, *cands):\n",
    "    for c in cands:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "M2C = {\n",
    "    # canonical OU markets from your repo\n",
    "    \"rush_yds\":         pick(dfs, \"rushing_yards\", \"rush_yards\"),\n",
    "    \"recv_yds\":         pick(dfs, \"receiving_yards\", \"rec_yards\", \"reception_yards\"),\n",
    "    \"receptions\":       pick(dfs, \"receptions\"),\n",
    "    \"pass_yds\":         pick(dfs, \"passing_yards\", \"pass_yards\"),\n",
    "    \"rush_attempts\":    pick(dfs, \"rush_attempts\", \"rushing_attempts\", \"carries\"),\n",
    "    \"pass_attempts\":    pick(dfs, \"passing_attempts\", \"pass_att\", \"attempts\"),\n",
    "    \"pass_completions\": pick(dfs, \"passing_completions\", \"pass_comp\", \"completions\"),\n",
    "    # Poisson-ish\n",
    "    \"pass_tds\":         pick(dfs, \"passing_tds\"),\n",
    "    \"interceptions\":    pick(dfs, \"interceptions\", \"passing_interceptions\", \"pass_interceptions\", \"ints\"),\n",
    "    # optional longest (if you want to grade these too)\n",
    "    \"reception_longest\": pick(dfs, \"receiving_long\", \"rec_long\", \"long_rec\"),\n",
    "    \"rush_longest\":      pick(dfs, \"rushing_long\", \"rush_long\", \"long_rush\"),\n",
    "    # Yes/No\n",
    "    \"anytime_td\":       None,  # computed from parts\n",
    "}\n",
    "\n",
    "td_parts = [c for c in [\n",
    "    \"total_tds\",\"rushing_tds\",\"receiving_tds\",\n",
    "    \"kick_return_tds\",\"punt_return_tds\",\"defensive_tds\",\"special_teams_tds\"\n",
    "] if c in dfs.columns]\n",
    "\n",
    "dfs_slice_cols = {\"name_std\"} | {c for c in M2C.values() if c} | set(td_parts)\n",
    "dfs_slice = dfs[list(dfs_slice_cols)].copy()\n",
    "# If a book encoded anytime TD as Over/Under, convert to Yes/No\n",
    "mask_at = merged[\"market_std\"].eq(\"anytime_td\") & merged[\"side\"].isin([\"Over\",\"Under\"])\n",
    "merged.loc[mask_at & merged[\"side\"].eq(\"Over\"),  \"side\"] = \"Yes\"\n",
    "merged.loc[mask_at & merged[\"side\"].eq(\"Under\"), \"side\"] = \"No\"\n",
    "\n",
    "# --- 4) Merge ---\n",
    "merged = dfp.merge(dfs_slice, on=\"name_std\", how=\"left\", suffixes=(\"\",\"_act\"))\n",
    "print(f\"[merge] rows: {len(merged):,}\")\n",
    "\n",
    "# --- 5) actual_value per market (index-safe) ---\n",
    "merged[\"actual_value\"] = np.nan\n",
    "for m, col in M2C.items():\n",
    "    if col:\n",
    "        sel = merged[\"market_std\"].eq(m)\n",
    "        if sel.any():\n",
    "            merged.loc[sel, \"actual_value\"] = pd.to_numeric(merged.loc[sel, col], errors=\"coerce\")\n",
    "\n",
    "# Anytime TD (binary), pandas-only to keep index alignment\n",
    "# --- Anytime TD (binary) — compute td_all (0/1) as an index-aligned Series\n",
    "sel_any = merged[\"market_std\"].eq(\"anytime_td\")\n",
    "td_all = None\n",
    "\n",
    "if sel_any.any():\n",
    "    if \"total_tds\" in merged.columns:\n",
    "        td_all = (\n",
    "            pd.to_numeric(merged[\"total_tds\"], errors=\"coerce\")\n",
    "            .fillna(0)\n",
    "            .gt(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "    else:\n",
    "        td_cols = [\n",
    "            \"rushing_tds\",\"receiving_tds\",\"kick_return_tds\",\n",
    "            \"punt_return_tds\",\"defensive_tds\",\"special_teams_tds\"\n",
    "        ]\n",
    "        avail = [c for c in td_cols if c in merged.columns]\n",
    "        if avail:\n",
    "            td_frame = pd.concat(\n",
    "                [pd.to_numeric(merged[c], errors=\"coerce\").fillna(0) for c in avail],\n",
    "                axis=1\n",
    "            )\n",
    "            td_all = td_frame.sum(axis=1).gt(0).astype(int)\n",
    "        else:\n",
    "            td_all = pd.Series(0, index=merged.index, dtype=\"int64\")\n",
    "\n",
    "    # Write actual_value only for anytime rows (float for consistency)\n",
    "    merged.loc[sel_any, \"actual_value\"] = td_all.loc[sel_any].astype(float)\n",
    "\n",
    "    # Derive actual_side directly from td_all (no astype on NaNs)\n",
    "    yes_idx = td_all.index[sel_any & td_all.eq(1)]\n",
    "    no_idx  = td_all.index[sel_any & td_all.eq(0)]\n",
    "    merged.loc[yes_idx, \"actual_side\"] = \"Yes\"\n",
    "    merged.loc[no_idx,  \"actual_side\"] = \"No\"\n",
    "\n",
    "\n",
    "# --- 6) Derive actual_side (ensure column is object dtype BEFORE assignment) ---\n",
    "merged[\"actual_side\"] = pd.Series(pd.NA, index=merged.index, dtype=\"object\")\n",
    "\n",
    "OU = {\n",
    "    \"rush_yds\",\"recv_yds\",\"receptions\",\"pass_yds\",\n",
    "    \"rush_attempts\",\"pass_attempts\",\"pass_completions\",\n",
    "    \"pass_tds\",\"interceptions\",\"reception_longest\",\"rush_longest\"\n",
    "}\n",
    "ou_mask = merged[\"market_std\"].isin(OU) & merged[\"line\"].notna() & merged[\"actual_value\"].notna()\n",
    "\n",
    "# Assign using masks (strings into object column => no dtype complaint)\n",
    "merged.loc[ou_mask & (merged[\"actual_value\"] > merged[\"line\"]), \"actual_side\"] = \"Over\"\n",
    "merged.loc[ou_mask & (merged[\"actual_value\"] < merged[\"line\"]), \"actual_side\"] = \"Under\"\n",
    "merged.loc[ou_mask & (merged[\"actual_value\"] == merged[\"line\"]), \"actual_side\"] = \"Push\"\n",
    "\n",
    "any_mask = merged[\"market_std\"].eq(\"anytime_td\") & merged[\"actual_value\"].notna()\n",
    "merged.loc[any_mask & merged[\"actual_value\"].notna() & (merged[\"actual_value\"] > 0),  \"actual_side\"] = \"Yes\"\n",
    "merged.loc[any_mask & merged[\"actual_value\"].notna() & (merged[\"actual_value\"] == 0), \"actual_side\"] = \"No\"\n",
    "\n",
    "print(\"[coverage] with actual_side:\", int(merged[\"actual_side\"].notna().sum()))\n",
    "print(\"[coverage] pushes:\", int((merged[\"actual_side\"]==\"Push\").sum()))\n",
    "\n",
    "# --- 7) Grade (ignore Push; require a declared side) ---\n",
    "mask_grade = merged[\"actual_side\"].notna() & merged[\"side\"].notna() & (merged[\"actual_side\"]!=\"Push\")\n",
    "merged[\"hit\"] = np.where(mask_grade & (merged[\"side\"] == merged[\"actual_side\"]), 1,\n",
    "                  np.where(mask_grade, 0, np.nan))\n",
    "\n",
    "print(\"[debug] stage counts\")\n",
    "print(\"  total rows         :\", len(merged))\n",
    "print(\"  has line           :\", int(merged[\"line\"].notna().sum()))\n",
    "print(\"  has actual_value   :\", int(merged[\"actual_value\"].notna().sum()))\n",
    "print(\"  OU gradeable rows  :\", int(ou_mask.sum()))\n",
    "print(\"  anytime gradeable  :\", int(any_mask.sum()))\n",
    "print(\"  side present       :\", int(merged[\"side\"].notna().sum()))\n",
    "print(\"  mask_grade rows    :\", int(mask_grade.sum()))\n",
    "\n",
    "if merged[\"hit\"].notna().any():\n",
    "    hit_rate = merged.loc[merged[\"hit\"].notna(),\"hit\"].mean()\n",
    "    print(f\"[hit-rate] {hit_rate:.3f} on {int(merged['hit'].notna().sum())} graded rows\")\n",
    "else:\n",
    "    print(\"[hit-rate] no graded rows — check debug counts above.\")\n",
    "\n",
    "# Prob metrics if model_prob exists and valid\n",
    "if \"model_prob\" in merged.columns:\n",
    "    mprob_mask = mask_grade & merged[\"model_prob\"].between(0,1)\n",
    "    if mprob_mask.any():\n",
    "        y = (merged.loc[mprob_mask, \"actual_side\"].isin([\"Over\",\"Yes\"])).astype(int)\n",
    "        p = merged.loc[mprob_mask, \"model_prob\"].astype(float)\n",
    "        print(f\"[brier] {brier_score_loss(y,p):.3f}   [logloss] {log_loss(y,p,labels=[0,1]):.3f}   (n={int(mprob_mask.sum())})\")\n",
    "    else:\n",
    "        print(\"[prob] no rows with valid model_prob in [0,1]\")\n",
    "else:\n",
    "    print(\"[prob] model_prob not present; skipping prob metrics\")\n",
    "\n",
    "# --- 8) Save outputs\n",
    "OUT = ROOT/\"data/eval\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "merged.to_csv(OUT/\"grades_week2.csv\", index=False)\n",
    "by_market = (merged.loc[mask_grade]\n",
    "             .groupby(\"market_std\")\n",
    "             .agg(rows=(\"hit\",\"count\"), hit_rate=(\"hit\",\"mean\"))\n",
    "             .sort_values([\"hit_rate\",\"rows\"], ascending=[False, False]))\n",
    "by_market.to_csv(OUT/\"grades_week2_by_market.csv\")\n",
    "print(\"[write]\", OUT/\"grades_week2.csv\")\n",
    "print(\"[write]\", OUT/\"grades_week2_by_market.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301b992-6f18-4feb-a172-fa6f82c8bfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
