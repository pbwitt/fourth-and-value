{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f5c4e8",
   "metadata": {},
   "source": [
    "\n",
    "# Fourth & Value — QC: Actuals vs Model\n",
    "\n",
    "**Purpose:** Grade weekly props by comparing **model probabilities/lines** to **game outcomes**, so we can trust and explain our edges.\n",
    "\n",
    "**What you get:**\n",
    "- Robust merge of `props_with_model_week{WEEK}.csv` ↔ `data/actuals/week{WEEK}.csv` with key fallbacks.\n",
    "- Coverage report (how many rows are gradeable by market).\n",
    "- Proper scoring rules: **Brier** and **Log Loss**, plus **hit rate** (for sanity).\n",
    "- Calibration table & plot (are 60% calls winning ~60%?).\n",
    "- CSV outputs in `data/eval/` for dashboards.\n",
    "- Clean, surgical cells so you can tweak any step.\n",
    "\n",
    "> Created: 2025-09-16 18:45 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8d39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params OK → {'SEASON': 2025, 'WEEK': 2}\n",
      "Paths: props_with_model_week2.csv week2.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== Parameters (edit these) ================================================\n",
    "SEASON = 2025\n",
    "WEEK   = 2   # <— change this as needed\n",
    "\n",
    "# Paths (relative to repo root)\n",
    "PROPS_CSV   = f\"props_with_model_week{WEEK}.csv\"\n",
    "ACTUALS_CSV = f\"week{WEEK}.csv\"\n",
    "\n",
    "# Where to write outputs\n",
    "EVAL_DIR          = \"data/eval\"\n",
    "GRADES_CSV        = f\"{EVAL_DIR}/grades_week{WEEK}.csv\"\n",
    "GRADES_BY_MKT_CSV = f\"{EVAL_DIR}/grades_week{WEEK}_by_market.csv\"\n",
    "COVERAGE_CSV      = f\"{EVAL_DIR}/coverage_week{WEEK}.csv\"\n",
    "CALIB_CSV         = f\"{EVAL_DIR}/calibration_week{WEEK}.csv\"\n",
    "\n",
    "# ==== Imports ================================================================\n",
    "import os, math, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create eval dir if missing\n",
    "Path(EVAL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Params OK →\", dict(SEASON=SEASON, WEEK=WEEK))\n",
    "print(\"Paths:\", PROPS_CSV, ACTUALS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f59d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[props] shape: (2673, 24)\n",
      "[actuals] shape: (160, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            game_id         commence_time       home_team  \\\n",
       " 0  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       " 1  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       " \n",
       "               away_team                                   game   bookmaker  \\\n",
       " 0  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       " 1  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       " \n",
       "   bookmaker_title         market market_std        player  ...   player_key  \\\n",
       " 0      DraftKings  player_1st_td   first_td  Bucky Irving  ...  buckyirving   \n",
       " 1      DraftKings  player_1st_td   first_td    Nick Chubb  ...    nickchubb   \n",
       " \n",
       "    point_key  mu sigma lam  mkt_prob  model_prob  edge_bps  season  week  \n",
       " 0        NaN NaN   NaN NaN  0.153846         NaN       NaN    2025     2  \n",
       " 1        NaN NaN   NaN NaN  0.142857         NaN       NaN    2025     2  \n",
       " \n",
       " [2 rows x 24 columns],\n",
       "   player_key name  market_std side  point  actual_value  result\n",
       " 0  joshallen  yes  anytime_td  yes    NaN           0.0     0.0\n",
       " 1  joshallen  yes  anytime_td   no    NaN           0.0     1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Load ===================================================================\n",
    "dfp = pd.read_csv(PROPS_CSV)\n",
    "dfa = pd.read_csv(ACTUALS_CSV)\n",
    "\n",
    "print(\"[props] shape:\", dfp.shape)\n",
    "print(\"[actuals] shape:\", dfa.shape)\n",
    "dfp.head(2), dfa.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8c813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[normalize] done.\n",
      "[normalize] done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== Helpers: market + name normalization ===================================\n",
    "\n",
    "ALIAS = {\n",
    "    # Markets\n",
    "    \"reception_yds\": \"recv_yds\",\n",
    "    \"receiving_yds\": \"recv_yds\",\n",
    "    \"rushing_yds\": \"rush_yds\",\n",
    "    \"passing_yds\": \"pass_yds\",\n",
    "    \"passing_tds\": \"pass_tds\",\n",
    "    \"interceptions\": \"pass_ints\",\n",
    "    \"player_first_td\": \"first_td\",\n",
    "    \"player_1st_td\": \"first_td\",\n",
    "    \"anytime_touchdown\": \"anytime_td\",\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "def std_market(x: str) -> str:\n",
    "    if pd.isna(x): return x\n",
    "    x = str(x).strip().lower()\n",
    "    return ALIAS.get(x, x)\n",
    "\n",
    "def std_name(x: str) -> str:\n",
    "    if pd.isna(x): return x\n",
    "    x = str(x).strip()\n",
    "    # light standardization (avoid being too lossy)\n",
    "    x = \" \".join(x.split())\n",
    "    return x\n",
    "\n",
    "def coalesce(*vals):\n",
    "    for v in vals:\n",
    "        if v is not None and not (isinstance(v, float) and math.isnan(v)):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "# Normalize markets and names in both frames\n",
    "for col in [\"market_std\", \"market\", \"market_name\"]:\n",
    "    if col in dfp.columns:\n",
    "        dfp[col] = dfp[col].apply(std_market)\n",
    "    if col in dfa.columns:\n",
    "        dfa[col] = dfa[col].apply(std_market)\n",
    "\n",
    "# standard name columns\n",
    "for col in [\"player\", \"name\", \"player_name\"]:\n",
    "    if col in dfp.columns:\n",
    "        dfp[col] = dfp[col].apply(std_name)\n",
    "    if col in dfa.columns:\n",
    "        dfa[col] = dfa[col].apply(std_name)\n",
    "\n",
    "# === Make guaranteed keys (vectorized, no Python `or` on Series) =============\n",
    "\n",
    "def first_nonnull_series(df: pd.DataFrame, candidates) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return the first non-null value across the candidate columns, row-wise.\n",
    "    If none of the columns exist, return a NA series of correct length.\n",
    "    \"\"\"\n",
    "    s = None\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            s = df[c] if s is None else s.combine_first(df[c])\n",
    "    if s is None:\n",
    "        s = pd.Series(pd.NA, index=df.index)\n",
    "    return s\n",
    "\n",
    "# name_std (player/name/player_name fallback)\n",
    "dfp[\"name_std\"] = first_nonnull_series(dfp, [\"name_std\", \"player\", \"name\", \"player_name\"]).apply(std_name)\n",
    "dfa[\"name_std\"] = first_nonnull_series(dfa, [\"name_std\", \"player\", \"name\", \"player_name\"]).apply(std_name)\n",
    "\n",
    "# market_std (market/market_name fallback, then normalize)\n",
    "dfp[\"market_std\"] = first_nonnull_series(dfp, [\"market_std\", \"market\", \"market_name\"]).apply(std_market)\n",
    "dfa[\"market_std\"] = first_nonnull_series(dfa, [\"market_std\", \"market\", \"market_name\"]).apply(std_market)\n",
    "\n",
    "# point/line keys (safe guards)\n",
    "if (\"point_key\" not in dfp.columns) and (\"line\" in dfp.columns):\n",
    "    dfp[\"point_key\"] = dfp[\"line\"]\n",
    "if (\"point_key\" not in dfa.columns) and (\"line\" in dfa.columns):\n",
    "    dfa[\"point_key\"] = dfa[\"line\"]\n",
    "\n",
    "print(\"[normalize] done.\")\n",
    "\n",
    "if \"point_key\" not in dfp.columns and \"line\" in dfp.columns:\n",
    "    dfp[\"point_key\"] = dfp[\"line\"]\n",
    "if \"point_key\" not in dfa.columns and \"line\" in dfa.columns:\n",
    "    dfa[\"point_key\"] = dfa[\"line\"]\n",
    "\n",
    "print(\"[normalize] done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d029e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using merge keys: ['player_key', 'market_std']\n",
      "[merge] merged rows: 2829  matched (has any _act col): 236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>commence_time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>game</th>\n",
       "      <th>bookmaker</th>\n",
       "      <th>bookmaker_title</th>\n",
       "      <th>market</th>\n",
       "      <th>market_std</th>\n",
       "      <th>player</th>\n",
       "      <th>...</th>\n",
       "      <th>model_prob</th>\n",
       "      <th>edge_bps</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>name_act</th>\n",
       "      <th>side</th>\n",
       "      <th>point_act</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>result</th>\n",
       "      <th>name_std_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>first_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>first_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Nick Chubb</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7d9a04f411031528d9c1d2df7b9a0453</td>\n",
       "      <td>2025-09-15T23:01:00Z</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Tampa Bay Buccaneers @ Houston Texans</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>first_td</td>\n",
       "      <td>first_td</td>\n",
       "      <td>Nico Collins</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            game_id         commence_time       home_team  \\\n",
       "0  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "1  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "2  7d9a04f411031528d9c1d2df7b9a0453  2025-09-15T23:01:00Z  Houston Texans   \n",
       "\n",
       "              away_team                                   game   bookmaker  \\\n",
       "0  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "1  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "2  Tampa Bay Buccaneers  Tampa Bay Buccaneers @ Houston Texans  draftkings   \n",
       "\n",
       "  bookmaker_title    market market_std        player  ... model_prob  \\\n",
       "0      DraftKings  first_td   first_td  Bucky Irving  ...        NaN   \n",
       "1      DraftKings  first_td   first_td    Nick Chubb  ...        NaN   \n",
       "2      DraftKings  first_td   first_td  Nico Collins  ...        NaN   \n",
       "\n",
       "   edge_bps  season week name_act  side  point_act  actual_value  result  \\\n",
       "0       NaN    2025    2      NaN   NaN        NaN           NaN     NaN   \n",
       "1       NaN    2025    2      NaN   NaN        NaN           NaN     NaN   \n",
       "2       NaN    2025    2      NaN   NaN        NaN           NaN     NaN   \n",
       "\n",
       "   name_std_act  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Merge with fallbacks ====================================================\n",
    "\n",
    "# Best key set (if available)\n",
    "keys = []\n",
    "if all(k in dfp.columns for k in [\"player_key\", \"market_std\", \"point_key\"]) and \\\n",
    "   all(k in dfa.columns for k in [\"player_key\", \"market_std\", \"point_key\"]):\n",
    "    keys = [\"player_key\", \"market_std\", \"point_key\"]\n",
    "elif all(k in dfp.columns for k in [\"player_key\", \"market_std\"]) and \\\n",
    "     all(k in dfa.columns for k in [\"player_key\", \"market_std\"]):\n",
    "    keys = [\"player_key\", \"market_std\"]\n",
    "else:\n",
    "    # name fallback\n",
    "    keys = [\"name_std\", \"market_std\"]\n",
    "    if \"point_key\" in dfp.columns and \"point_key\" in dfa.columns:\n",
    "        keys.append(\"point_key\")\n",
    "\n",
    "print(\"Using merge keys:\", keys)\n",
    "merged = dfp.merge(\n",
    "    dfa,\n",
    "    how=\"left\",\n",
    "    on=[k for k in keys if k in dfp.columns and k in dfa.columns],\n",
    "    suffixes=(\"\", \"_act\")\n",
    ")\n",
    "\n",
    "matched = merged[\"market_std\"].notna() & merged.filter(regex=\"_act$\").any(axis=1)\n",
    "print(\"[merge] merged rows:\", len(merged), \" matched (has any _act col):\", int(matched.sum()))\n",
    "merged.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894e194b-7389-428d-ace0-00d39af45f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ensure canonical numeric `line` exists ==================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def first_existing_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# pick the first available source for the betting line\n",
    "line_src = first_existing_col(merged, [\"line\", \"point\", \"point_key\", \"book_line\", \"offer_line\", \"line_disp\"])\n",
    "if line_src is None:\n",
    "    merged[\"line\"] = np.nan\n",
    "else:\n",
    "    merged[\"line\"] = merged[line_src]\n",
    "    # parse strings like \"Over 65.5 (-110)\" or \"o65.5\" to numeric 65.5\n",
    "    if merged[\"line\"].dtype == object:\n",
    "        parsed = (\n",
    "            merged[\"line\"].astype(str)\n",
    "            .str.extract(r\"(-?\\d+(?:\\.\\d+)?)\", expand=False)\n",
    "        )\n",
    "        merged[\"line\"] = pd.to_numeric(parsed, errors=\"coerce\")\n",
    "\n",
    "# normalize side to just 'over'/'under' if not already\n",
    "if \"side\" not in merged.columns:\n",
    "    guess = first_existing_col(merged, [\"side\", \"bet\", \"selection\", \"wager\", \"pick\"])\n",
    "    merged[\"side\"] = merged[guess] if guess else np.nan\n",
    "merged[\"side\"] = merged[\"side\"].astype(str).str.lower().str.extract(r\"(over|under|yes|no)\", expand=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7ead9d-19ed-488e-8bb9-96522607feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals columns (first 60):\n",
      "['player_key', 'name', 'market_std', 'side', 'point', 'actual_value', 'result', 'name_std']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>player_key</th>\n",
       "      <td>joshallen</td>\n",
       "      <td>joshallen</td>\n",
       "      <td>jamescook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_std</th>\n",
       "      <td>anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_value</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_std</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0           1           2\n",
       "player_key     joshallen   joshallen   jamescook\n",
       "name                 yes         yes         yes\n",
       "market_std    anytime_td  anytime_td  anytime_td\n",
       "side                 yes          no         yes\n",
       "point                NaN         NaN         NaN\n",
       "actual_value         0.0         0.0         2.0\n",
       "result               0.0         1.0         1.0\n",
       "name_std             yes         yes         yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto-guessed ACTUALS_MAP (only markets we could match):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_line</th>\n",
       "      <th>has_actual</th>\n",
       "      <th>has_side</th>\n",
       "      <th>has_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_std</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anytime_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_attempts</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_completions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_tds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receptions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recv_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_attempts</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_ints</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reception_longest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_longest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   has_line  has_actual  has_side  has_prob\n",
       "market_std                                                 \n",
       "anytime_td              0.0    0.340548       0.0       1.0\n",
       "pass_attempts           1.0    0.000000       0.0       1.0\n",
       "pass_completions        1.0    0.000000       0.0       1.0\n",
       "pass_tds                1.0    0.000000       0.0       1.0\n",
       "pass_yds                1.0    0.000000       0.0       1.0\n",
       "receptions              1.0    0.000000       0.0       1.0\n",
       "recv_yds                1.0    0.000000       0.0       1.0\n",
       "rush_attempts           1.0    0.000000       0.0       1.0\n",
       "rush_yds                1.0    0.000000       0.0       1.0\n",
       "first_td                0.0    0.000000       0.0       0.0\n",
       "last_td                 0.0    0.000000       0.0       0.0\n",
       "pass_ints               1.0    0.000000       0.0       0.0\n",
       "reception_longest       1.0    0.000000       0.0       0.0\n",
       "rush_longest            1.0    0.000000       0.0       0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Inspect actuals + auto-map columns to markets ===========================\n",
    "import re\n",
    "\n",
    "print(\"Actuals columns (first 60):\")\n",
    "print(dfa.columns.tolist()[:60])\n",
    "display(dfa.head(3).T)\n",
    "\n",
    "# Heuristics for column detection (ordered by preference)\n",
    "CANDIDATES = {\n",
    "    \"pass_yds\":        [\"passing_yards\",\"pass_yards\",\"pass_yds\",\"yards_passing\"],\n",
    "    \"rush_yds\":        [\"rushing_yards\",\"rush_yards\",\"rush_yds\",\"yards_rushing\"],\n",
    "    \"recv_yds\":        [\"receiving_yards\",\"recv_yards\",\"recv_yds\",\"yards_receiving\",\"reception_yards\"],\n",
    "    \"receptions\":      [\"receptions\",\"rec\",\"rec_cnt\"],\n",
    "    \"pass_completions\":[\"completions\",\"pass_completions\",\"cmp\"],\n",
    "    \"pass_attempts\":   [\"attempts\",\"pass_attempts\",\"att\"],\n",
    "    \"rush_attempts\":   [\"carries\",\"rush_attempts\",\"rush_att\"],\n",
    "    \"pass_tds\":        [\"passing_tds\",\"pass_tds\",\"td_pass\"],\n",
    "    \"pass_ints\":       [\"interceptions\",\"int_thrown\",\"pass_ints\"],\n",
    "    # optional longest:\n",
    "    \"reception_longest\":[\"longest_reception\",\"long_rec\",\"long_reception\"],\n",
    "    \"rush_longest\":    [\"longest_rush\",\"long_rush\",\"long_rushing\"],\n",
    "}\n",
    "\n",
    "present = set(dfa.columns.str.lower())\n",
    "def pick(cands):\n",
    "    for c in cands:\n",
    "        if c.lower() in present:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "ACTUALS_MAP = {mkt: [col] for mkt in CANDIDATES\n",
    "               if (col := pick(CANDIDATES[mkt])) is not None}\n",
    "\n",
    "print(\"\\nAuto-guessed ACTUALS_MAP (only markets we could match):\")\n",
    "for k,v in ACTUALS_MAP.items():\n",
    "    print(f\"  {k:18s} <- {v[0]}\")\n",
    "\n",
    "# Helpers used earlier\n",
    "def first_existing_series(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return pd.Series(np.nan, index=df.index)\n",
    "\n",
    "# Ensure actual_value column exists\n",
    "if \"actual_value\" not in merged.columns:\n",
    "    merged[\"actual_value\"] = np.nan\n",
    "\n",
    "# Fill actual_value from the guessed map\n",
    "for mkt, cand_cols in ACTUALS_MAP.items():\n",
    "    mask = merged[\"market_std\"].eq(mkt)\n",
    "    if mask.any():\n",
    "        series = first_existing_series(merged, cand_cols)\n",
    "        merged.loc[mask, \"actual_value\"] = merged.loc[mask, \"actual_value\"].fillna(series)\n",
    "\n",
    "# Normalize side text → over/under\n",
    "def first_existing_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "if \"side\" not in merged.columns:\n",
    "    guess = first_existing_col(merged, [\"bet\",\"selection\",\"wager\",\"pick\"])\n",
    "    merged[\"side\"] = merged[guess] if guess else np.nan\n",
    "\n",
    "merged[\"side\"] = (\n",
    "    merged[\"side\"].astype(str).str.lower()\n",
    "    .str.extract(r\"(over|under)\", expand=False)\n",
    ")\n",
    "\n",
    "# Recompute the quick debug table\n",
    "dbg = (merged\n",
    "       .assign(has_line=merged[\"line\"].notna(),\n",
    "               has_actual=merged[\"actual_value\"].notna(),\n",
    "               has_side=merged[\"side\"].isin([\"over\",\"under\"]),\n",
    "               has_prob=(merged[\"model_prob\"].notna() if \"model_prob\" in merged.columns else False))\n",
    "       .groupby(\"market_std\")[[\"has_line\",\"has_actual\",\"has_side\",\"has_prob\"]]\n",
    "       .mean()\n",
    "       .sort_values([\"has_actual\",\"has_side\",\"has_prob\"], ascending=False))\n",
    "dbg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d3c98b-e4fa-4d7e-8041-5b0ceebb2358",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Missing data/weekly_player_stats_2025.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m STATS = Path(\u001b[33m\"\u001b[39m\u001b[33mdata/weekly_player_stats_2025.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m STATS.exists():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing data/weekly_player_stats_2025.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m stats = pd.read_parquet(STATS)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Narrow to the week/season you’re grading\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Missing data/weekly_player_stats_2025.parquet"
     ]
    }
   ],
   "source": [
    "# === Backfill O/U actuals from nflverse weekly player stats ==================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "STATS = Path(\"data/weekly_player_stats_2025.parquet\")\n",
    "if not STATS.exists():\n",
    "    raise FileNotFoundError(\"Missing data/weekly_player_stats_2025.parquet\")\n",
    "\n",
    "stats = pd.read_parquet(STATS)\n",
    "# Narrow to the week/season you’re grading\n",
    "if {\"week\",\"season\"}.issubset(stats.columns):\n",
    "    stats = stats[(stats[\"week\"] == WEEK) & (stats[\"season\"] == SEASON)]\n",
    "\n",
    "# Minimal columns (rename to our canonical names)\n",
    "rename_map = {\n",
    "    \"passing_yards\": \"pass_yds\",\n",
    "    \"rushing_yards\": \"rush_yds\",\n",
    "    \"receiving_yards\": \"recv_yds\",\n",
    "    \"receptions\": \"receptions\",\n",
    "    \"completions\": \"pass_completions\",\n",
    "    \"attempts\": \"pass_attempts\",\n",
    "    \"carries\": \"rush_attempts\",\n",
    "    \"passing_tds\": \"pass_tds\",\n",
    "    \"interceptions\": \"pass_ints\",\n",
    "}\n",
    "have = [c for c in rename_map if c in stats.columns]\n",
    "use = stats[[\"player_key\"] + have].rename(columns=rename_map)\n",
    "\n",
    "# For each O/U market, fill merged['actual_value'] by joining on player_key\n",
    "for mkt in use.columns.drop(\"player_key\"):\n",
    "    mask = merged[\"market_std\"].eq(mkt)\n",
    "    if mask.any():\n",
    "        # join only the subset we need to reduce work\n",
    "        sub = merged.loc[mask, [\"player_key\"]].merge(use[[\"player_key\", mkt]], on=\"player_key\", how=\"left\")\n",
    "        merged.loc[mask, \"actual_value\"] = merged.loc[mask, \"actual_value\"].fillna(sub[mkt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457a7dc2-e916-46b5-b9a4-f0bd061e8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Canonicalize line, side, actual scaffolding =============================\n",
    "\n",
    "def first_existing_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# numeric line\n",
    "line_src = first_existing_col(merged, [\"line\",\"point\",\"point_key\",\"book_line\",\"offer_line\",\"line_disp\"])\n",
    "merged[\"line\"] = np.nan if line_src is None else merged[line_src]\n",
    "if merged[\"line\"].dtype == object:\n",
    "    merged[\"line\"] = merged[\"line\"].astype(str).str.extract(r\"(-?\\d+(?:\\.\\d+)?)\", expand=False).astype(float)\n",
    "\n",
    "# side → over/under (handle \"Over 65.5\", \"o65.5\", \"UNDER\", etc.)\n",
    "if \"side\" not in merged.columns:\n",
    "    guess = first_existing_col(merged, [\"bet\",\"wager\",\"selection\"])\n",
    "    merged[\"side\"] = merged[guess] if guess else np.nan\n",
    "\n",
    "merged[\"side\"] = (\n",
    "    merged[\"side\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"^\\s*o(?![a-z])\", \"over\", regex=True)\n",
    "    .str.replace(r\"^\\s*u(?![a-z])\", \"under\", regex=True)\n",
    "    .str.extract(r\"(over|under|yes|no)\", expand=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a706fb5d-8d0d-468f-a535-16ad36cc1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Map actuals columns to markets ==========================================\n",
    "ACTUALS_MAP = {\n",
    "    # yards / counts\n",
    "    \"pass_yds\":        [\"pass_yds\",\"passing_yds\",\"passing_yards\",\"yards_passing\"],\n",
    "    \"rush_yds\":        [\"rush_yds\",\"rushing_yds\",\"rushing_yards\",\"yards_rushing\"],\n",
    "    \"recv_yds\":        [\"recv_yds\",\"receiving_yds\",\"reception_yds\",\"receiving_yards\",\"yards_receiving\"],\n",
    "    \"receptions\":      [\"receptions\",\"rec\",\"rec_cnt\"],\n",
    "    \"pass_completions\":[\"pass_completions\",\"completions\",\"pass_cmp\",\"cmp\"],\n",
    "    \"pass_attempts\":   [\"pass_attempts\",\"attempts\",\"pass_att\",\"att\"],\n",
    "    \"rush_attempts\":   [\"rush_attempts\",\"carries\",\"rush_att\"],\n",
    "    \"pass_tds\":        [\"pass_tds\",\"passing_tds\",\"passing_touchdowns\",\"td_pass\"],\n",
    "    \"pass_ints\":       [\"pass_ints\",\"interceptions\",\"interceptions_thrown\",\"int_thrown\"],\n",
    "    # longest props (optional)\n",
    "    \"reception_longest\":[\"long_rec\",\"longest_reception\",\"long_reception\"],\n",
    "    \"rush_longest\":    [\"long_rush\",\"longest_rush\",\"long_rushing\"],\n",
    "}\n",
    "\n",
    "def first_existing_series(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return pd.Series(np.nan, index=df.index)\n",
    "\n",
    "# If merged already had some 'actual_value', don't destroy good values.\n",
    "if \"actual_value\" not in merged.columns:\n",
    "    merged[\"actual_value\"] = np.nan\n",
    "\n",
    "for mkt, cand_cols in ACTUALS_MAP.items():\n",
    "    mask = merged[\"market_std\"].eq(mkt)\n",
    "    if mask.any():\n",
    "        series = first_existing_series(merged, cand_cols)\n",
    "        merged.loc[mask, \"actual_value\"] = merged.loc[mask, \"actual_value\"].fillna(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54137202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gradeable] rows: 236\n",
      "Markets graded:\n",
      " market_std\n",
      "anytime_td    236\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>commence_time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>game</th>\n",
       "      <th>bookmaker</th>\n",
       "      <th>bookmaker_title</th>\n",
       "      <th>market</th>\n",
       "      <th>market_std</th>\n",
       "      <th>player</th>\n",
       "      <th>...</th>\n",
       "      <th>week</th>\n",
       "      <th>name_act</th>\n",
       "      <th>side</th>\n",
       "      <th>point_act</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>result</th>\n",
       "      <th>name_std_act</th>\n",
       "      <th>line</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>actual_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>aca5234c57e31b1931e51d2d0d6046f5</td>\n",
       "      <td>2025-09-19T00:15:00Z</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>Miami Dolphins @ Buffalo Bills</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>aca5234c57e31b1931e51d2d0d6046f5</td>\n",
       "      <td>2025-09-19T00:15:00Z</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>Miami Dolphins @ Buffalo Bills</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>aca5234c57e31b1931e51d2d0d6046f5</td>\n",
       "      <td>2025-09-19T00:15:00Z</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>Miami Dolphins @ Buffalo Bills</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>player_anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               game_id         commence_time      home_team  \\\n",
       "2499  aca5234c57e31b1931e51d2d0d6046f5  2025-09-19T00:15:00Z  Buffalo Bills   \n",
       "2500  aca5234c57e31b1931e51d2d0d6046f5  2025-09-19T00:15:00Z  Buffalo Bills   \n",
       "2501  aca5234c57e31b1931e51d2d0d6046f5  2025-09-19T00:15:00Z  Buffalo Bills   \n",
       "\n",
       "           away_team                            game   bookmaker  \\\n",
       "2499  Miami Dolphins  Miami Dolphins @ Buffalo Bills  draftkings   \n",
       "2500  Miami Dolphins  Miami Dolphins @ Buffalo Bills  draftkings   \n",
       "2501  Miami Dolphins  Miami Dolphins @ Buffalo Bills  draftkings   \n",
       "\n",
       "     bookmaker_title             market  market_std      player  ... week  \\\n",
       "2499      DraftKings  player_anytime_td  anytime_td  Josh Allen  ...    2   \n",
       "2500      DraftKings  player_anytime_td  anytime_td  Josh Allen  ...    2   \n",
       "2501      DraftKings  player_anytime_td  anytime_td  Josh Allen  ...    2   \n",
       "\n",
       "      name_act  side point_act actual_value  result  name_std_act  line  \\\n",
       "2499       yes   NaN       NaN          0.0     0.0           yes   NaN   \n",
       "2500       yes   NaN       NaN          0.0     1.0           yes   NaN   \n",
       "2501       yes   NaN       NaN          0.0     0.0           yes   NaN   \n",
       "\n",
       "      pred_prob  actual_bin  \n",
       "2499   0.221199         0.0  \n",
       "2500   0.221199         0.0  \n",
       "2501   0.221199         0.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Compute gradeable outcomes (using long-format actuals) ==================\n",
    "\n",
    "model_prob_col = \"model_prob\" if \"model_prob\" in merged.columns else None\n",
    "\n",
    "merged[\"pred_prob\"]  = np.nan\n",
    "merged[\"actual_bin\"] = np.nan\n",
    "\n",
    "# Binary markets (anytime_td, first_td, last_td)\n",
    "mask_bin = merged[\"market_std\"].isin([\"anytime_td\",\"first_td\",\"last_td\"]) & (model_prob_col is not None)\n",
    "if mask_bin.any():\n",
    "    merged.loc[mask_bin, \"pred_prob\"]  = merged.loc[mask_bin, model_prob_col]\n",
    "    # For binary markets, actual_value is already 0/1\n",
    "    merged.loc[mask_bin, \"actual_bin\"] = merged.loc[mask_bin, \"actual_value\"].clip(0,1).astype(float)\n",
    "\n",
    "# O/U markets: actual_value + side + point are already in actuals\n",
    "OU_MARKETS = {\n",
    "    \"pass_yds\",\"rush_yds\",\"recv_yds\",\"receptions\",\n",
    "    \"pass_completions\",\"pass_attempts\",\"rush_attempts\",\n",
    "    \"pass_tds\",\"pass_ints\"\n",
    "}\n",
    "mask_ou = merged[\"market_std\"].isin(OU_MARKETS) & merged[\"line\"].notna() & merged[\"actual_value\"].notna() & merged[\"side\"].notna()\n",
    "\n",
    "side_over  = mask_ou & merged[\"side\"].str.lower().eq(\"over\")\n",
    "side_under = mask_ou & merged[\"side\"].str.lower().eq(\"under\")\n",
    "\n",
    "merged.loc[side_over,  \"actual_bin\"] = (merged.loc[side_over,  \"actual_value\"] >= merged.loc[side_over,  \"line\"]).astype(int)\n",
    "merged.loc[side_under, \"actual_bin\"] = (merged.loc[side_under, \"actual_value\"] <= merged.loc[side_under,  \"line\"]).astype(int)\n",
    "\n",
    "if model_prob_col:\n",
    "    merged.loc[mask_ou & merged[model_prob_col].notna(), \"pred_prob\"] = merged.loc[mask_ou, model_prob_col]\n",
    "\n",
    "# Done\n",
    "gradeable = merged[\"pred_prob\"].notna() & merged[\"actual_bin\"].notna()\n",
    "graded = merged.loc[gradeable].copy()\n",
    "\n",
    "print(\"[gradeable] rows:\", len(graded))\n",
    "print(\"Markets graded:\\n\", graded[\"market_std\"].value_counts())\n",
    "graded.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe70453-6803-479d-b3c8-9c27c63a65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present: ['actual_bin', 'actual_value', 'away_team', 'bookmaker', 'bookmaker_title', 'commence_time', 'edge_bps', 'game', 'game_id', 'home_team', 'lam', 'line', 'market', 'market_std', 'mkt_prob', 'model_prob', 'mu', 'name', 'name_act', 'name_std', 'name_std_act', 'player', 'player_key', 'point', 'point_act', 'point_key', 'pred_prob', 'price', 'result', 'season'] ...\n",
      "{'market_std': np.float64(1.0), 'line': np.float64(0.5083068221986567), 'actual_value': np.float64(0.08342170378225522), 'side': np.float64(0.0), 'model_prob': np.float64(0.6408624955814776)}\n",
      "side unique: Series([], Name: count, dtype: int64)\n",
      "sample lines: ['32.5', '32.5', '32.5', '32.5', '21.5']\n",
      "markets w/ rows: market_std\n",
      "anytime_td           693\n",
      "first_td             430\n",
      "recv_yds             336\n",
      "receptions           320\n",
      "last_td              268\n",
      "reception_longest    184\n",
      "rush_yds             150\n",
      "rush_longest          88\n",
      "rush_attempts         82\n",
      "pass_tds              62\n",
      "pass_yds              62\n",
      "pass_attempts         54\n",
      "pass_completions      54\n",
      "pass_ints             46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === DIAGNOSTICS ==============================================================\n",
    "print(\"Columns present:\", sorted(merged.columns.tolist())[:30], \"...\")\n",
    "\n",
    "need = [\"market_std\",\"line\",\"actual_value\",\"side\",\"model_prob\"]\n",
    "print({c: merged[c].notna().mean() if c in merged.columns else 0 for c in need})\n",
    "\n",
    "print(\"side unique:\", merged.get(\"side\", pd.Series(dtype=str)).dropna().astype(str).str.lower().value_counts().head(10))\n",
    "print(\"sample lines:\", merged.get(\"line\", pd.Series(dtype=float)).dropna().astype(str).head(5).tolist())\n",
    "\n",
    "print(\"markets w/ rows:\", merged[\"market_std\"].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9a44e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': 236,\n",
       " 'hit_rate@0.5': 0.7203389830508474,\n",
       " 'brier': 0.204868514609762,\n",
       " 'logloss': 0.602006958743382}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Scoring =================================================================\n",
    "\n",
    "def brier_score(p: np.ndarray, y: np.ndarray) -> float:\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    return float(np.mean((p - y)**2))\n",
    "\n",
    "def log_loss(p: np.ndarray, y: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    p = np.clip(np.asarray(p, dtype=float), eps, 1 - eps)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    return float(-np.mean(y*np.log(p) + (1-y)*np.log(1-p)))\n",
    "\n",
    "def hit_rate(p: np.ndarray, y: np.ndarray, threshold: float = 0.5) -> float:\n",
    "    return float(np.mean(((p >= threshold).astype(int) == y.astype(int))))\n",
    "\n",
    "if len(graded) == 0:\n",
    "    raise SystemExit(\"No gradeable rows. Check that model_prob & actuals are present.\")\n",
    "\n",
    "overall = {\n",
    "    \"rows\": len(graded),\n",
    "    \"hit_rate@0.5\": hit_rate(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "    \"brier\": brier_score(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "    \"logloss\": log_loss(graded[\"pred_prob\"], graded[\"actual_bin\"]),\n",
    "}\n",
    "overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd504b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_std</th>\n",
       "      <th>rows</th>\n",
       "      <th>hit_rate@0.5</th>\n",
       "      <th>brier</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anytime_td</td>\n",
       "      <td>236</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.602007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_std  rows  hit_rate@0.5     brier   logloss\n",
       "0  anytime_td   236      0.720339  0.204869  0.602007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Per-market performance ==================================================\n",
    "def summarize_by_market(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for mkt, g in df.groupby(\"market_std\"):\n",
    "        rows.append({\n",
    "            \"market_std\": mkt,\n",
    "            \"rows\": len(g),\n",
    "            \"hit_rate@0.5\": hit_rate(g[\"pred_prob\"], g[\"actual_bin\"]),\n",
    "            \"brier\": brier_score(g[\"pred_prob\"], g[\"actual_bin\"]),\n",
    "            \"logloss\": log_loss(g[\"pred_prob\"], g[\"actual_bin\"]),\n",
    "        })\n",
    "    out = pd.DataFrame(rows).sort_values([\"brier\",\"logloss\",\"rows\"], ascending=[True, True, False])\n",
    "    return out\n",
    "\n",
    "by_market = summarize_by_market(graded)\n",
    "by_market.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af943363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_std</th>\n",
       "      <th>total_rows</th>\n",
       "      <th>gradeable_rows</th>\n",
       "      <th>coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anytime_td</td>\n",
       "      <td>693</td>\n",
       "      <td>236</td>\n",
       "      <td>0.340548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_td</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last_td</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pass_attempts</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pass_completions</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pass_ints</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pass_tds</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pass_yds</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reception_longest</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>receptions</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>recv_yds</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rush_attempts</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rush_longest</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rush_yds</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           market_std  total_rows  gradeable_rows  coverage_pct\n",
       "0          anytime_td         693             236      0.340548\n",
       "1            first_td         430               0      0.000000\n",
       "2             last_td         268               0      0.000000\n",
       "3       pass_attempts          54               0      0.000000\n",
       "4    pass_completions          54               0      0.000000\n",
       "5           pass_ints          46               0      0.000000\n",
       "6            pass_tds          62               0      0.000000\n",
       "7            pass_yds          62               0      0.000000\n",
       "8   reception_longest         184               0      0.000000\n",
       "9          receptions         320               0      0.000000\n",
       "10           recv_yds         336               0      0.000000\n",
       "11      rush_attempts          82               0      0.000000\n",
       "12       rush_longest          88               0      0.000000\n",
       "13           rush_yds         150               0      0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Coverage report =========================================================\n",
    "def coverage_table(df_all: pd.DataFrame, df_gradeable: pd.DataFrame) -> pd.DataFrame:\n",
    "    cov = (df_all.assign(is_gradeable=False)\n",
    "                 .assign(is_gradeable=lambda d: d.index.isin(df_gradeable.index)))\n",
    "    rows = []\n",
    "    for mkt, g in cov.groupby(\"market_std\"):\n",
    "        rows.append({\n",
    "            \"market_std\": mkt,\n",
    "            \"total_rows\": len(g),\n",
    "            \"gradeable_rows\": int(g[\"is_gradeable\"].sum()),\n",
    "            \"coverage_pct\": (g[\"is_gradeable\"].mean() if len(g) else 0.0),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"coverage_pct\", ascending=False)\n",
    "\n",
    "coverage = coverage_table(merged, graded)\n",
    "coverage.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ed5494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/h0vxhn1x3vz5nph_c0qc60t00000gn/T/ipykernel_74624/3069823878.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agg = df.groupby(cut).agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>n</th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>emp_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.22097, 0.22102]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.22102, 0.22107]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.22107, 0.22111]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.22111, 0.22115]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.22115, 0.2212]</td>\n",
       "      <td>236</td>\n",
       "      <td>0.221199</td>\n",
       "      <td>0.279661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.2212, 0.22124]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.22124, 0.22129]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.22129, 0.22133]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.22133, 0.22138]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.22138, 0.22142]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             avg_pred    n  avg_pred  emp_rate\n",
       "0  (0.22097, 0.22102]    0       NaN       NaN\n",
       "1  (0.22102, 0.22107]    0       NaN       NaN\n",
       "2  (0.22107, 0.22111]    0       NaN       NaN\n",
       "3  (0.22111, 0.22115]    0       NaN       NaN\n",
       "4   (0.22115, 0.2212]  236  0.221199  0.279661\n",
       "5   (0.2212, 0.22124]    0       NaN       NaN\n",
       "6  (0.22124, 0.22129]    0       NaN       NaN\n",
       "7  (0.22129, 0.22133]    0       NaN       NaN\n",
       "8  (0.22133, 0.22138]    0       NaN       NaN\n",
       "9  (0.22138, 0.22142]    0       NaN       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== Calibration =============================================================\n",
    "def calibration_bins(df: pd.DataFrame, bins=10) -> pd.DataFrame:\n",
    "    cut = pd.cut(df[\"pred_prob\"], bins=bins, include_lowest=True)\n",
    "    agg = df.groupby(cut).agg(\n",
    "        n=(\"actual_bin\",\"size\"),\n",
    "        avg_pred=(\"pred_prob\",\"mean\"),\n",
    "        emp_rate=(\"actual_bin\",\"mean\"),\n",
    "    ).reset_index().rename(columns={\"pred_prob\":\"avg_pred\"})\n",
    "    return agg\n",
    "\n",
    "calib = calibration_bins(graded, bins=10)\n",
    "calib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd4b8db-f315-4d31-beb0-b51615024acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_line</th>\n",
       "      <th>has_actual</th>\n",
       "      <th>has_side</th>\n",
       "      <th>has_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_std</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anytime_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_td</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_attempts</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_completions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_ints</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_tds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reception_longest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receptions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recv_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_attempts</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_longest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush_yds</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   has_line  has_actual  has_side  has_prob\n",
       "market_std                                                 \n",
       "anytime_td              0.0    0.340548       0.0       1.0\n",
       "first_td                0.0    0.000000       0.0       0.0\n",
       "last_td                 0.0    0.000000       0.0       0.0\n",
       "pass_attempts           1.0    0.000000       0.0       1.0\n",
       "pass_completions        1.0    0.000000       0.0       1.0\n",
       "pass_ints               1.0    0.000000       0.0       0.0\n",
       "pass_tds                1.0    0.000000       0.0       1.0\n",
       "pass_yds                1.0    0.000000       0.0       1.0\n",
       "reception_longest       1.0    0.000000       0.0       0.0\n",
       "receptions              1.0    0.000000       0.0       1.0\n",
       "recv_yds                1.0    0.000000       0.0       1.0\n",
       "rush_attempts           1.0    0.000000       0.0       1.0\n",
       "rush_longest            1.0    0.000000       0.0       0.0\n",
       "rush_yds                1.0    0.000000       0.0       1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbg = (merged\n",
    "       .assign(has_line=merged[\"line\"].notna(),\n",
    "               has_actual=merged[\"actual_value\"].notna(),\n",
    "               has_side=merged[\"side\"].isin([\"over\",\"under\"]),\n",
    "               has_prob=(merged[model_prob_col].notna() if model_prob_col else False))\n",
    "       .groupby(\"market_std\")[[\"has_line\",\"has_actual\",\"has_side\",\"has_prob\"]]\n",
    "       .mean()\n",
    "       .sort_values(\"has_actual\", ascending=False))\n",
    "dbg.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ae095e-f371-4f48-ba8d-3e5427b6afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals columns: ['player_key', 'name', 'market_std', 'side', 'point', 'actual_value', 'result', 'name_std']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>player_key</th>\n",
       "      <td>joshallen</td>\n",
       "      <td>joshallen</td>\n",
       "      <td>jamescook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_std</th>\n",
       "      <td>anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "      <td>anytime_td</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_value</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_std</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0           1           2\n",
       "player_key     joshallen   joshallen   jamescook\n",
       "name                 yes         yes         yes\n",
       "market_std    anytime_td  anytime_td  anytime_td\n",
       "side                 yes          no         yes\n",
       "point                NaN         NaN         NaN\n",
       "actual_value         0.0         0.0         2.0\n",
       "result               0.0         1.0         1.0\n",
       "name_std             yes         yes         yes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actuals columns:\", dfa.columns.tolist()[:40])\n",
    "dfa.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed181174-a050-4c60-ab06-eb38326d8eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[QC] coverage flags by market:\n",
      "                    has_line  has_actual  has_side  has_prob\n",
      "market_std                                                 \n",
      "anytime_td              0.0       0.341       0.0       1.0\n",
      "pass_attempts           1.0       0.000       0.0       1.0\n",
      "pass_completions        1.0       0.000       0.0       1.0\n",
      "pass_tds                1.0       0.000       0.0       1.0\n",
      "pass_yds                1.0       0.000       0.0       1.0\n",
      "receptions              1.0       0.000       0.0       1.0\n",
      "recv_yds                1.0       0.000       0.0       1.0\n",
      "rush_attempts           1.0       0.000       0.0       1.0\n",
      "rush_yds                1.0       0.000       0.0       1.0\n",
      "first_td                0.0       0.000       0.0       0.0\n",
      "last_td                 0.0       0.000       0.0       0.0\n",
      "pass_ints               1.0       0.000       0.0       0.0\n",
      "reception_longest       1.0       0.000       0.0       0.0\n",
      "rush_longest            1.0       0.000       0.0       0.0\n",
      "\n",
      "[QC] overall: {'rows': 236, 'hit_rate@0.5': 0.7203389830508474, 'brier': 0.204868514609762, 'logloss': 0.602006958743382}\n",
      "\n",
      "[QC] per-market head:\n",
      "    market_std  rows  hit_rate@0.5     brier   logloss\n",
      "0  anytime_td   236      0.720339  0.204869  0.602007\n",
      "\n",
      "[wrote] data/eval/qc_flags_week2.csv\n",
      "[wrote] data/eval/qc_summary_week2.json\n",
      "[wrote] data/eval/qc_summary_week2.txt\n",
      "[wrote] data/eval/grades_by_market_week2.csv\n"
     ]
    }
   ],
   "source": [
    "# === Quick shareables =========================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "OUT = Path(\"data/eval\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Mini debug table (rounded)\n",
    "dbg_out = (\n",
    "    merged.assign(\n",
    "        has_line = merged.get(\"line\").notna() if \"line\" in merged.columns else False,\n",
    "        has_actual = merged.get(\"actual_value\").notna() if \"actual_value\" in merged.columns else False,\n",
    "        has_side = merged.get(\"side\").isin([\"over\",\"under\"]) if \"side\" in merged.columns else False,\n",
    "        has_prob = merged.get(\"model_prob\").notna() if \"model_prob\" in merged.columns else False,\n",
    "    )\n",
    "    .groupby(\"market_std\")[[\"has_line\",\"has_actual\",\"has_side\",\"has_prob\"]]\n",
    "    .mean()\n",
    "    .round(3)\n",
    "    .sort_values([\"has_actual\",\"has_side\",\"has_prob\"], ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n[QC] coverage flags by market:\\n\", dbg_out.head(20))\n",
    "dbg_out.to_csv(OUT/f\"qc_flags_week{WEEK}.csv\")\n",
    "\n",
    "# 2) Overall metrics dict (if 'graded' exists)\n",
    "overall_dict = {}\n",
    "if \"graded\" in globals() and len(graded):\n",
    "    overall_dict = {\n",
    "        \"rows\": int(len(graded)),\n",
    "        \"hit_rate@0.5\": float(hit_rate(graded[\"pred_prob\"], graded[\"actual_bin\"])),\n",
    "        \"brier\": float(brier_score(graded[\"pred_prob\"], graded[\"actual_bin\"])),\n",
    "        \"logloss\": float(log_loss(graded[\"pred_prob\"], graded[\"actual_bin\"])),\n",
    "    }\n",
    "    print(\"\\n[QC] overall:\", overall_dict)\n",
    "\n",
    "# 3) Per-market snapshot\n",
    "per_mkt = by_market if \"by_market\" in globals() else None\n",
    "if per_mkt is not None:\n",
    "    print(\"\\n[QC] per-market head:\\n\", per_mkt.head(10))\n",
    "    per_mkt.to_csv(OUT/f\"grades_by_market_week{WEEK}.csv\", index=False)\n",
    "\n",
    "# 4) Write a tiny JSON + TXT summary\n",
    "summary = {\n",
    "    \"week\": WEEK,\n",
    "    \"overall\": overall_dict,\n",
    "    \"top_markets\": (per_mkt.head(5).to_dict(\"records\") if per_mkt is not None and len(per_mkt) else []),\n",
    "}\n",
    "(OUT/f\"qc_summary_week{WEEK}.json\").write_text(json.dumps(summary, indent=2))\n",
    "(OUT/f\"qc_summary_week{WEEK}.txt\").write_text(\n",
    "    f\"Week {WEEK}\\nOverall: {overall_dict}\\n\\nTop markets:\\n\" +\n",
    "    \"\\n\".join(f\"- {r['market_std']}: brier={r['brier']:.3f}, n={r['rows']}\" for r in summary[\"top_markets\"])\n",
    ")\n",
    "\n",
    "print(f\"\\n[wrote] {OUT}/qc_flags_week{WEEK}.csv\")\n",
    "print(f\"[wrote] {OUT}/qc_summary_week{WEEK}.json\")\n",
    "print(f\"[wrote] {OUT}/qc_summary_week{WEEK}.txt\")\n",
    "if per_mkt is not None:\n",
    "    print(f\"[wrote] {OUT}/grades_by_market_week{WEEK}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f849c507",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'pandas._libs.interval.Interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot calibration: avg_pred vs emp_rate\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(calib[\u001b[33m\"\u001b[39m\u001b[33mavg_pred\u001b[39m\u001b[33m\"\u001b[39m], calib[\u001b[33m\"\u001b[39m\u001b[33memp_rate\u001b[39m\u001b[33m\"\u001b[39m], marker=\u001b[33m\"\u001b[39m\u001b[33mo\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.plot([\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m],[\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m], linestyle=\u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mPredicted probability (bin avg)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gca().plot(\n\u001b[32m   3839\u001b[39m         *args,\n\u001b[32m   3840\u001b[39m         scalex=scalex,\n\u001b[32m   3841\u001b[39m         scaley=scaley,\n\u001b[32m   3842\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m   3843\u001b[39m         **kwargs,\n\u001b[32m   3844\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1779\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n\u001b[32m   1780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scalex:\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28mself\u001b[39m._request_autoscale_view(\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/axes/_base.py:2417\u001b[39m, in \u001b[36m_AxesBase.add_line\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m   2414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2415\u001b[39m     line.set_clip_path(\u001b[38;5;28mself\u001b[39m.patch)\n\u001b[32m-> \u001b[39m\u001b[32m2417\u001b[39m \u001b[38;5;28mself\u001b[39m._update_line_limits(line)\n\u001b[32m   2418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line.get_label():\n\u001b[32m   2419\u001b[39m     line.set_label(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_child\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._children)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/axes/_base.py:2440\u001b[39m, in \u001b[36m_AxesBase._update_line_limits\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m   2436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_line_limits\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[32m   2437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2438\u001b[39m \u001b[33;03m    Figures out the data limit of the given line, updating `.Axes.dataLim`.\u001b[39;00m\n\u001b[32m   2439\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2440\u001b[39m     path = line.get_path()\n\u001b[32m   2441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m path.vertices.size == \u001b[32m0\u001b[39m:\n\u001b[32m   2442\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/lines.py:1052\u001b[39m, in \u001b[36mLine2D.get_path\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invalidy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invalidx:\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28mself\u001b[39m.recache()\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/lines.py:689\u001b[39m, in \u001b[36mLine2D.recache\u001b[39m\u001b[34m(self, always)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m always \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invalidx:\n\u001b[32m    688\u001b[39m     xconv = \u001b[38;5;28mself\u001b[39m.convert_xunits(\u001b[38;5;28mself\u001b[39m._xorig)\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m     x = _to_unmasked_float_array(xconv).ravel()\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    691\u001b[39m     x = \u001b[38;5;28mself\u001b[39m._x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/matplotlib/cbook.py:1355\u001b[39m, in \u001b[36m_to_unmasked_float_array\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.ma.asarray(x, \u001b[38;5;28mfloat\u001b[39m).filled(np.nan)\n\u001b[32m   1354\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(x, \u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'pandas._libs.interval.Interval'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot calibration: avg_pred vs emp_rate\n",
    "plt.figure()\n",
    "plt.plot(calib[\"avg_pred\"], calib[\"emp_rate\"], marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted probability (bin avg)\")\n",
    "plt.ylabel(\"Empirical win rate\")\n",
    "plt.title(f\"Calibration — Week {WEEK}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5077e-7118-40b2-845c-75facf82a739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2621f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Save outputs ============================================================\n",
    "graded_out = graded.copy()\n",
    "graded_out.to_csv(GRADES_CSV, index=False)\n",
    "by_market.to_csv(GRADES_BY_MKT_CSV, index=False)\n",
    "coverage.to_csv(COVERAGE_CSV, index=False)\n",
    "calib.to_csv(CALIB_CSV, index=False)\n",
    "\n",
    "print(\"[write]\", GRADES_CSV)\n",
    "print(\"[write]\", GRADES_BY_MKT_CSV)\n",
    "print(\"[write]\", COVERAGE_CSV)\n",
    "print(\"[write]\", CALIB_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9015a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== CEO-ready summary string ===============================================\n",
    "def pct(x: float) -> str:\n",
    "    return f\"{x:.1%}\"\n",
    "\n",
    "summary = (\n",
    "    f\"Week {WEEK} — graded {overall['rows']} props. \"\n",
    "    f\"Hit-rate@0.5={pct(overall['hit_rate@0.5'])}, \"\n",
    "    f\"Brier={overall['brier']:.3f}, LogLoss={overall['logloss']:.3f}. \"\n",
    ")\n",
    "\n",
    "# Best/worst markets by Brier (min => better)\n",
    "best = by_market.sort_values(\"brier\").head(3).to_dict(orient=\"records\")\n",
    "worst = by_market.sort_values(\"brier\").tail(3).to_dict(orient=\"records\")\n",
    "\n",
    "summary += \" Best markets: \" + \", \".join(f\"{r['market_std']} (Brier {r['brier']:.3f}, n={r['rows']})\" for r in best) + \".\"\n",
    "summary += \" Needs work: \" + \", \".join(f\"{r['market_std']} (Brier {r['brier']:.3f}, n={r['rows']})\" for r in worst) + \".\"\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d032d",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps / Tweaks\n",
    "- If your **actuals** encode outcomes differently (e.g., `\"scored\": True/False`), adjust the conversion in the Outcome cell.\n",
    "- To grade **profitability**, join your stakes and realized odds, then compute ROI by applying your bet policy to `pred_prob` vs book.\n",
    "- Add per-team or per-book breakdowns if you need operational insights.\n",
    "- Consider weekly archiving: keep `grades_week{W}.csv` to drive historical charts on the site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63607d4-d2fc-4085-85bf-ce3807e556ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
