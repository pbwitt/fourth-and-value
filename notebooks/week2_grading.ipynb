{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b9f212",
   "metadata": {},
   "source": [
    "# Week 2 — Model vs Actuals: Grading Notebook 📊\n",
    "\n",
    "This notebook evaluates **Week 2** props predictions against realized outcomes to identify best‑performing markets (and overall performance).\n",
    "\n",
    "**Inputs**\n",
    "- `data/props/props_with_model_week2.csv` (model outputs + book market)\n",
    "- `data/actuals/week2.csv` (built earlier)\n",
    "\n",
    "**Outputs**\n",
    "- `data/eval/grades_week2.csv` — row-level joined dataset with metrics\n",
    "- `data/eval/market_perf_week2.csv` — per-market summary (hit rate, Brier, ROI, etc.)\n",
    "\n",
    "**Metrics**\n",
    "- Accuracy (hit rate)\n",
    "- Brier score (lower is better)\n",
    "- Log loss (lower is better; ignores rows with p∈{0,1})\n",
    "- ROI per $1 using market odds when available (fallback from mkt_prob)\n",
    "- Edge direction capture rate (did results agree with model edge sign?)\n",
    "- Correlation between `model_prob` and outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719d57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[paths]\n",
      " props   : False /Users/pwitt/fourth-and-value/notebooks/data/props/props_with_model_week2.csv\n",
      " actuals : False /Users/pwitt/fourth-and-value/notebooks/data/actuals/week2.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Missing inputs; ensure Week 2 props and actuals exist.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m Missing inputs; ensure Week 2 props and actuals exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pwitt/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "WEEK = 2\n",
    "BASE = Path.cwd()\n",
    "\n",
    "props_path   = BASE / f\"data/props/props_with_model_week{WEEK}.csv\"\n",
    "actuals_path = BASE / f\"data/actuals/week{WEEK}.csv\"\n",
    "out_grades   = BASE / f\"data/eval/grades_week{WEEK}.csv\"\n",
    "out_markets  = BASE / f\"data/eval/market_perf_week{WEEK}.csv\"\n",
    "\n",
    "print(\"[paths]\")\n",
    "print(\" props   :\", props_path.exists(), props_path)\n",
    "print(\" actuals :\", actuals_path.exists(), actuals_path)\n",
    "\n",
    "if not props_path.exists() or not actuals_path.exists():\n",
    "    raise SystemExit(\"Missing inputs; ensure Week 2 props and actuals exist.\")\n",
    "    \n",
    "dfp = pd.read_csv(props_path)\n",
    "dfa = pd.read_csv(actuals_path)\n",
    "print(\"[shape] props:\", dfp.shape, \" actuals:\", dfa.shape)\n",
    "\n",
    "# normalize key columns\n",
    "def has(df, cols): return all(c in df.columns for c in cols)\n",
    "\n",
    "join_cols = [\"player_key\",\"market_std\",\"side\"]\n",
    "use_point = \"point_key\" in dfp.columns and \"point_key\" in dfa.columns\n",
    "if use_point:\n",
    "    join_cols += [\"point_key\"]\n",
    "\n",
    "missing = [c for c in join_cols if c not in dfp.columns or c not in dfa.columns]\n",
    "if missing:\n",
    "    # fallback: ignore point_key if missing\n",
    "    join_cols = [c for c in [\"player_key\",\"market_std\",\"side\"] if c in dfp.columns and c in dfa.columns]\n",
    "    print(\"[warn] using fallback join keys:\", join_cols)\n",
    "\n",
    "merged = dfp.merge(dfa, on=join_cols, how=\"left\", suffixes=(\"\", \"_act\"))\n",
    "print(\"[merge] rows:\", len(merged), \" matched results:\", merged[\"result\"].notna().sum())\n",
    "\n",
    "# Helper conversions\n",
    "def amer_to_prob(oa):\n",
    "    if pd.isna(oa): return np.nan\n",
    "    oa = float(oa)\n",
    "    return (-oa)/((-oa)+100.0) if oa < 0 else 100.0/(oa+100.0)\n",
    "\n",
    "def amer_to_decimal(oa):\n",
    "    if pd.isna(oa): return np.nan\n",
    "    oa = float(oa)\n",
    "    return (1 + 100.0/(-oa)) if oa < 0 else (1 + oa/100.0)\n",
    "\n",
    "# Column mapping\n",
    "c_side  = next((c for c in [\"side\",\"bet_side\",\"ou_side\",\"yes_no_side\"] if c in merged.columns), \"side\")\n",
    "c_pmod  = next((c for c in [\"model_prob\",\"model_p\",\"p_model\",\"pred_prob\"] if c in merged.columns), None)\n",
    "c_pbook = next((c for c in [\"mkt_prob\",\"consensus_prob\",\"book_implied_prob\"] if c in merged.columns), None)\n",
    "c_odds  = next((c for c in [\"odds_american\",\"mkt_odds_american\",\"american_odds\",\"price\"] if c in merged.columns), None)\n",
    "\n",
    "if c_pmod is None:\n",
    "    raise SystemExit(\"Missing model probability column (expected one of model_prob/model_p/p_model/pred_prob)\")\n",
    "\n",
    "# Coerce probs\n",
    "merged[c_pmod]  = pd.to_numeric(merged[c_pmod], errors=\"coerce\").clip(0,1)\n",
    "if c_pbook: merged[c_pbook] = pd.to_numeric(merged[c_pbook], errors=\"coerce\").clip(0,1)\n",
    "if c_odds:\n",
    "    merged[c_odds] = pd.to_numeric(merged[c_odds], errors=\"coerce\")\n",
    "\n",
    "# Fill market prob from odds if needed\n",
    "if c_pbook and merged[c_pbook].isna().any():\n",
    "    merged[c_pbook] = merged[c_pbook].fillna(merged[c_odds].apply(amer_to_prob) if c_odds else np.nan)\n",
    "\n",
    "# Effective model vs market probs conditioned on side (UNDER/NO gets 1-p)\n",
    "side = merged[c_side].astype(str).str.lower()\n",
    "yes_like = side.isin([\"over\",\"yes\"])\n",
    "p_model_eff = merged[c_pmod].where(yes_like, 1.0 - merged[c_pmod])\n",
    "p_mkt_eff   = (merged[c_pbook].where(yes_like, 1.0 - merged[c_pbook])) if c_pbook else np.nan\n",
    "\n",
    "# Metrics per row\n",
    "merged[\"brier\"] = (merged[c_pmod] - merged[\"result\"])**2\n",
    "eps = 1e-9\n",
    "p_safe = merged[c_pmod].clip(eps, 1-eps)\n",
    "merged[\"logloss\"] = -(merged[\"result\"]*np.log(p_safe) + (1-merged[\"result\"])*np.log(1-p_safe))\n",
    "\n",
    "# ROI using odds if available, else implied from mkt_prob\n",
    "if c_odds:\n",
    "    merged[\"decimal_odds\"] = merged[c_odds].apply(amer_to_decimal)\n",
    "else:\n",
    "    merged[\"decimal_odds\"] = np.nan\n",
    "\n",
    "no_price = merged[\"decimal_odds\"].isna()\n",
    "if no_price.any():\n",
    "    # fair odds from consensus prob (no-vig approx)\n",
    "    if c_pbook:\n",
    "        merged.loc[no_price & merged[c_pbook].gt(0), \"decimal_odds\"] = 1.0 / merged.loc[no_price, c_pbook]\n",
    "\n",
    "merged[\"ev_realized_per_$1\"] = merged[\"result\"] * (merged[\"decimal_odds\"] - 1.0) - (1 - merged[\"result\"]) * 1.0\n",
    "\n",
    "# Edge sign capture\n",
    "merged[\"edge_dir\"] = (p_model_eff - p_mkt_eff) if c_pbook else np.nan\n",
    "merged[\"edge_hit\"] = (((merged[\"edge_dir\"] > 0) & (merged[\"result\"] == 1)) | ((merged[\"edge_dir\"] < 0) & (merged[\"result\"] == 0))).astype(\"float\")\n",
    "\n",
    "# Correlation (model prob vs result)\n",
    "try:\n",
    "    corr = float(pd.Series(merged[c_pmod]).corr(pd.Series(merged[\"result\"])))\n",
    "except Exception:\n",
    "    corr = np.nan\n",
    "\n",
    "print(f\"[overall] rows={len(merged)}  hit={merged['result'].mean():.3f}  \"\n",
    "      f\"brier={merged['brier'].mean():.4f}  logloss={merged['logloss'].mean():.4f}  \"\n",
    "      f\"roi/1={merged['ev_realized_per_$1'].mean():.4f}  corr(p, y)={corr:.3f}\")\n",
    "\n",
    "# Write out grades (selected columns)\n",
    "keep = [\"player_key\",\"market_std\",\"side\",\"point_key\"] if \"point_key\" in merged.columns else [\"player_key\",\"market_std\",\"side\"]\n",
    "keep += [c for c in [c_pmod, c_pbook, c_odds, \"decimal_odds\", \"result\", \"brier\", \"logloss\", \"edge_dir\", \"edge_hit\", \"ev_realized_per_$1\"] if c in merged.columns]\n",
    "grades = merged[keep].copy()\n",
    "out_grades.parent.mkdir(parents=True, exist_ok=True)\n",
    "grades.to_csv(out_grades, index=False)\n",
    "print(\"[write] grades ->\", out_grades)\n",
    "grades.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b104c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1229647912.py, line 13)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mroi_per_$1=(\"ev_realized_per_$1\", safemean),\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Per-market summary: hit rate, Brier, log loss, edge_hit, ROI\n",
    "def safemean(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.dropna().mean()\n",
    "\n",
    "perf = grades.groupby(\"market_std\", dropna=False).agg(\n",
    "    n=(\"result\",\"count\"),\n",
    "    hit=(\"result\",\"mean\"),\n",
    "    brier=(\"brier\", safemean),\n",
    "    logloss=(\"logloss\", safemean),\n",
    "    edge_hit_rate=(\"edge_hit\", safemean),\n",
    "    avg_edge_dir=(\"edge_dir\", safemean),\n",
    "    roi_per_$1=(\"ev_realized_per_$1\", safemean),\n",
    ").reset_index()\n",
    "\n",
    "# Rank views\n",
    "top_by_roi   = perf.sort_values([\"roi_per_$1\",\"n\"], ascending=[False, False]).head(12)\n",
    "top_by_brier = perf.sort_values([\"brier\",\"n\"], ascending=[True, False]).head(12)\n",
    "\n",
    "display(perf.sort_values(\"roi_per_$1\", ascending=False).head(20))\n",
    "display(top_by_roi)\n",
    "display(top_by_brier)\n",
    "\n",
    "# Write market summary\n",
    "perf.to_csv(out_markets, index=False)\n",
    "print(\"[write] per-market ->\", out_markets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de2214",
   "metadata": {},
   "source": [
    "### Tweet-ready snippets\n",
    "\n",
    "Run the next cell to generate short, plain‑text summaries you can paste into a tweet or thread.\n",
    "- One “overall” line\n",
    "- Up to 5 best markets by ROI (min n=25 to avoid tiny samples; tweak as needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e20c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grades' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m overall = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(grades[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m].count()),\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(grades[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m].mean()),\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbrier\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(pd.to_numeric(grades[\u001b[33m\"\u001b[39m\u001b[33mbrier\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).mean()),\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(pd.to_numeric(grades[\u001b[33m\"\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).mean()),\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mroi\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(pd.to_numeric(grades[\u001b[33m\"\u001b[39m\u001b[33mev_realized_per_$1\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).mean()),\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m tweet_lines = []\n\u001b[32m     10\u001b[39m tweet_lines.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWk2 model vs actuals — n=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall[\u001b[33m'\u001b[39m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, hit=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall[\u001b[33m'\u001b[39m\u001b[33mhit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBrier=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall[\u001b[33m'\u001b[39m\u001b[33mbrier\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, LogLoss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall[\u001b[33m'\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ROI/1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall[\u001b[33m'\u001b[39m\u001b[33mroi\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'grades' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "overall = {\n",
    "    \"n\": int(grades[\"result\"].count()),\n",
    "    \"hit\": float(grades[\"result\"].mean()),\n",
    "    \"brier\": float(pd.to_numeric(grades[\"brier\"], errors=\"coerce\").mean()),\n",
    "    \"logloss\": float(pd.to_numeric(grades[\"logloss\"], errors=\"coerce\").mean()),\n",
    "    \"roi\": float(pd.to_numeric(grades[\"ev_realized_per_$1\"], errors=\"coerce\").mean()),\n",
    "}\n",
    "\n",
    "tweet_lines = []\n",
    "tweet_lines.append(f\"Wk2 model vs actuals — n={overall['n']}, hit={overall['hit']:.3f}, \"\n",
    "                   f\"Brier={overall['brier']:.3f}, LogLoss={overall['logloss']:.3f}, ROI/1={overall['roi']:.3f}.\")\n",
    "\n",
    "pf = perf.copy()\n",
    "pf = pf[pf[\"n\"] >= 25]  # avoid tiny samples\n",
    "pf = pf.sort_values(\"roi_per_$1\", ascending=False).head(5)\n",
    "for _, r in pf.iterrows():\n",
    "    tweet_lines.append(f\"{r['market_std']}: n={int(r['n'])}, hit={r['hit']:.3f}, ROI/1={r['roi_per_$1']:.3f}, Brier={r['brier']:.3f}\")\n",
    "\n",
    "print(\"\\n\".join(tweet_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b912b9",
   "metadata": {},
   "source": [
    "### (Optional) Simple bar chart — ROI by market\n",
    "\n",
    "> Uses matplotlib (no styles/colors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e45b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pf = perf.sort_values(\"roi_per_$1\", ascending=False).head(12)\n",
    "plt.figure()\n",
    "plt.bar(pf[\"market_std\"].astype(str), pf[\"roi_per_$1\"])\n",
    "plt.title(\"Week 2 — ROI per $1 by Market (Top 12)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"ROI per $1\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
