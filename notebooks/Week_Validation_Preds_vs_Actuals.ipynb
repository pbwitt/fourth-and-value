{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa9b668",
   "metadata": {},
   "source": [
    "# Week Validation — Predictions vs Actuals\n",
    "\n",
    "Evaluate **model probabilities** against **actual outcomes** for a week.\n",
    "\n",
    "**It will:**\n",
    "1) Load merged predictions (edges) and the weekly stats parquet\n",
    "2) Normalize markets and players\n",
    "3) Compute binary outcome per prop (exclude pushes)\n",
    "4) Report **Brier**, **Log loss**, and **calibration** by market\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cae3d",
   "metadata": {},
   "source": [
    "## 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4369b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: data/props/props_with_model_week2.csv data/weekly_player_stats_2025.parquet\n"
     ]
    }
   ],
   "source": [
    "SEASON = 2025\n",
    "WEEK   = 2\n",
    "PATH_EDGES  = f'data/props/props_with_model_week{WEEK}.csv'\n",
    "PATH_WEEKLY = f'data/weekly_player_stats_{SEASON}.parquet'\n",
    "print('Using:', PATH_EDGES, PATH_WEEKLY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4c04d",
   "metadata": {},
   "source": [
    "## 1) Imports & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c35547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, numpy as np, pandas as pd\n",
    "try:\n",
    "    from common_markets import standardize_input as _std_input\n",
    "except Exception:\n",
    "    def _norm_side(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        if 'over' in s: return 'over'\n",
    "        if 'under' in s: return 'under'\n",
    "        if s in ('yes','no'): return s\n",
    "        return s\n",
    "    ALIAS = {\n",
    "        'player_anytime_td':'anytime_td',\n",
    "        'player_reception_yds':'recv_yds', 'player_receptions':'receptions',\n",
    "        'player_rush_yds':'rush_yds', 'player_rush_attempts':'rush_attempts',\n",
    "        'player_pass_yds':'pass_yds', 'player_pass_attempts':'pass_attempts',\n",
    "        'player_pass_completions':'pass_completions', 'player_pass_tds':'pass_tds',\n",
    "        'player_pass_interceptions':'interceptions', 'pass_interceptions':'interceptions',\n",
    "        'interceptions_thrown':'interceptions', 'ints':'interceptions', 'interception':'interceptions',\n",
    "    }\n",
    "    def _std_name(s):\n",
    "        s = re.sub(r\"[^a-z0-9\\s]\",\"\",str(s).lower())\n",
    "        s = re.sub(r\"\\s+\",\" \",s).strip()\n",
    "        return s\n",
    "    def _std_input(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        src = next((c for c in ['market_std','market','market_name','market_key','key','market_slug'] if c in df.columns), None)\n",
    "        if src is not None:\n",
    "            ms = df[src].astype(str).str.lower().str.strip()\n",
    "            df['market_std'] = ms.map(lambda x: ALIAS.get(x, x.replace('player_','')))\n",
    "        else:\n",
    "            df['market_std'] = ''\n",
    "        # side\n",
    "        s = None\n",
    "        for c in ('name','side','selection','bet_name','over_under','bet_side'):\n",
    "            if c in df.columns: s = df[c]; break\n",
    "        if s is not None:\n",
    "            df['name'] = s.astype(str).map(_norm_side)\n",
    "        elif 'name' not in df.columns:\n",
    "            df['name'] = pd.NA\n",
    "        # point\n",
    "        p = None\n",
    "        for c in ('point','line','odds_point','bet_line','points'):\n",
    "            if c in df.columns: p = df[c]; break\n",
    "        if p is not None:\n",
    "            df['point'] = pd.to_numeric(p, errors='coerce')\n",
    "        elif 'point' not in df.columns:\n",
    "            df['point'] = pd.NA\n",
    "        # player\n",
    "        pn = None\n",
    "        for c in ('player','player_name','athlete','athlete_name','name_player'):\n",
    "            if c in df.columns: pn = df[c]; break\n",
    "        if pn is not None:\n",
    "            s2 = pn.astype(str).map(_std_name)\n",
    "            df['name_std'] = s2\n",
    "            df['player_key'] = s2.str.replace(' ','-', regex=False)\n",
    "        else:\n",
    "            if 'name_std' not in df.columns: df['name_std'] = pd.NA\n",
    "            if 'player_key' not in df.columns: df['player_key'] = pd.NA\n",
    "        return df\n",
    "\n",
    "def brier(y_true, p):\n",
    "    y_true = np.asarray(y_true, float); p = np.asarray(p, float)\n",
    "    return np.mean((p - y_true)**2)\n",
    "def logloss(y_true, p, eps=1e-9):\n",
    "    y_true = np.asarray(y_true, float); p = np.clip(np.asarray(p, float), eps, 1-eps)\n",
    "    return -np.mean(y_true*np.log(p) + (1-y_true)*np.log(1-p))\n",
    "def calib_table(y_true, p, bins=10):\n",
    "    idx = np.clip((p * bins).astype(int), 0, bins-1)\n",
    "    df = pd.DataFrame({'bin':idx, 'p':p, 'y':y_true})\n",
    "    out = df.groupby('bin').agg(n=('y','size'), p_avg=('p','mean'), y_rate=('y','mean')).reset_index()\n",
    "    out['abs_gap'] = (out['p_avg'] - out['y_rate']).abs()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479ac3f",
   "metadata": {},
   "source": [
    "## 2) Load predictions & weekly actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47af6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: (14739, 24) weekly: (1142, 114)\n",
      "weekly (filtered): (71, 114)\n"
     ]
    }
   ],
   "source": [
    "edges  = pd.read_csv(PATH_EDGES, low_memory=False)\n",
    "weekly = pd.read_parquet(PATH_WEEKLY)\n",
    "print('edges:', edges.shape, 'weekly:', weekly.shape)\n",
    "edges = _std_input(edges)\n",
    "weekly.columns = [str(c).strip().lower() for c in weekly.columns]\n",
    "weekly_wk = weekly[(weekly.get('season',0)==SEASON) & (weekly.get('week',0)==WEEK)].copy() if 'season' in weekly.columns and 'week' in weekly.columns else weekly.copy()\n",
    "print('weekly (filtered):', weekly_wk.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d28fa",
   "metadata": {},
   "source": [
    "## 3) Map markets to stat columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f9fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recv_yds': 'receiving_yards',\n",
       " 'receptions': 'receptions',\n",
       " 'rush_yds': 'rushing_yards',\n",
       " 'rush_attempts': None,\n",
       " 'pass_yds': 'passing_yards',\n",
       " 'pass_attempts': 'attempts',\n",
       " 'pass_completions': 'completions',\n",
       " 'pass_tds': 'passing_tds',\n",
       " 'interceptions': None,\n",
       " 'anytime_td': '_any_td_dummy'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARKET_COLS = {\n",
    "  'recv_yds':        ['receiving_yards','rec_yds','rec_yards'],\n",
    "  'receptions':      ['receptions','rec'],\n",
    "  'rush_yds':        ['rushing_yards','rush_yds'],\n",
    "  'rush_attempts':   ['rushing_attempts','rush_att'],\n",
    "  'pass_yds':        ['passing_yards','pass_yds'],\n",
    "  'pass_attempts':   ['passing_attempts','attempts'],\n",
    "  'pass_completions':['completions','pass_completions','passing_completions'],\n",
    "  'pass_tds':        ['passing_tds','pass_tds'],\n",
    "  'interceptions':   ['interceptions','ints'],\n",
    "  'anytime_td':      ['_any_td_dummy'],\n",
    "}\n",
    "td_rush = weekly_wk['rushing_tds'] if 'rushing_tds' in weekly_wk.columns else 0\n",
    "td_rec  = weekly_wk['receiving_tds'] if 'receiving_tds' in weekly_wk.columns else 0\n",
    "weekly_wk['_any_td_dummy'] = ((pd.Series(td_rush).fillna(0) + pd.Series(td_rec).fillna(0)) >= 1).astype(int)\n",
    "actual_col = {m: next((c for c in cands if c in weekly_wk.columns), None) for m, cands in MARKET_COLS.items()}\n",
    "actual_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac60cd",
   "metadata": {},
   "source": [
    "## 4) Build per-player actuals for this week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1731aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _std_name(s):\n",
    "    s = re.sub(r'[^a-z0-9\\s]','',str(s).lower())\n",
    "    s = re.sub(r'\\s+',' ',' '.join(s.split())).strip()\n",
    "    return s\n",
    "pname_col = next((c for c in ['player','player_name','name'] if c in weekly_wk.columns), None)\n",
    "weekly_wk['name_std'] = weekly_wk[pname_col].map(_std_name) if pname_col else ''\n",
    "keep_cols = ['name_std']\n",
    "for c in actual_col.values():\n",
    "    if c:\n",
    "        keep_cols.append(c)\n",
    "keep_cols = [c for c in keep_cols if c in weekly_wk.columns]\n",
    "wk = weekly_wk[keep_cols].drop_duplicates('name_std').copy()\n",
    "wk.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1843251",
   "metadata": {},
   "source": [
    "## 5) Join predictions to actuals and compute outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1972a9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored rows: 0 of 14739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>commence_time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>game</th>\n",
       "      <th>bookmaker</th>\n",
       "      <th>bookmaker_title</th>\n",
       "      <th>market</th>\n",
       "      <th>market_std</th>\n",
       "      <th>player</th>\n",
       "      <th>...</th>\n",
       "      <th>receiving_yards</th>\n",
       "      <th>receptions</th>\n",
       "      <th>rushing_yards</th>\n",
       "      <th>passing_yards</th>\n",
       "      <th>attempts</th>\n",
       "      <th>completions</th>\n",
       "      <th>passing_tds</th>\n",
       "      <th>_any_td_dummy</th>\n",
       "      <th>actual</th>\n",
       "      <th>drop_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [game_id, commence_time, home_team, away_team, game, bookmaker, bookmaker_title, market, market_std, player, name, price, point, name_std, player_key, point_key, mu, sigma, lam, mkt_prob, model_prob, edge_bps, season, week, receiving_yards, receptions, rushing_yards, passing_yards, attempts, completions, passing_tds, _any_td_dummy, actual, drop_row]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = edges.copy()\n",
    "df['market_std'] = df['market_std'].astype(str).str.lower()\n",
    "df['name'] = df['name'].astype(str).str.lower().str.strip()\n",
    "df['point'] = pd.to_numeric(df.get('point', np.nan), errors='coerce')\n",
    "id_col = 'name_std' if 'name_std' in df.columns and 'name_std' in wk.columns else None\n",
    "if id_col is None:\n",
    "    raise RuntimeError('Could not find common identity column (name_std).')\n",
    "df = df.merge(wk, on=id_col, how='left', suffixes=('','_actual'))\n",
    "import numpy as np, pandas as pd\n",
    "def row_actual(r):\n",
    "    m = r['market_std']; a_col = actual_col.get(m)\n",
    "    if not a_col: return np.nan, True\n",
    "    val = r.get(a_col)\n",
    "    if pd.isna(val): return np.nan, True\n",
    "    side = r['name']\n",
    "    if m == 'anytime_td':\n",
    "        y = int(val >= 1)\n",
    "        return (1 if side == 'yes' else 0) if side in ('yes','no') else np.nan, False if side in ('yes','no') else True\n",
    "    if pd.isna(r['point']): return np.nan, True\n",
    "    if side == 'over':\n",
    "        if val == r['point']: return np.nan, True\n",
    "        return int(val > r['point']), False\n",
    "    if side == 'under':\n",
    "        if val == r['point']: return np.nan, True\n",
    "        return int(val < r['point']), False\n",
    "    return np.nan, True\n",
    "out = df.apply(lambda r: row_actual(r), axis=1, result_type='expand')\n",
    "df['actual'] = out[0]; df['drop_row'] = out[1].fillna(True)\n",
    "scored = df[(~df['drop_row']) & df['model_prob'].notna() & df['actual'].notna()].copy()\n",
    "print('Scored rows:', len(scored), 'of', len(df))\n",
    "scored.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e867e",
   "metadata": {},
   "source": [
    "## 6) Metrics by market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b11996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/h0vxhn1x3vz5nph_c0qc60t00000gn/T/ipykernel_2707/3924332218.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  report = (scored.groupby('market_std', as_index=False).apply(agg_market)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'brier'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/zm/h0vxhn1x3vz5nph_c0qc60t00000gn/T/ipykernel_2707/3924332218.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      9\u001b[39m     y = g[\u001b[33m'actual'\u001b[39m].astype(float).values\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m pandas \u001b[38;5;28;01mas\u001b[39;00m pd, numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.Series({\u001b[33m'n'\u001b[39m:len(g), \u001b[33m'avg_pred'\u001b[39m:np.mean(p), \u001b[33m'base_rate'\u001b[39m:np.mean(y), \u001b[33m'brier'\u001b[39m:brier(y,p), \u001b[33m'logloss'\u001b[39m:logloss(y,p), \u001b[33m'abs_calib_gap'\u001b[39m:abs(np.mean(p)-np.mean(y))})\n\u001b[32m     12\u001b[39m report = (scored.groupby('market_std', as_index=False).apply(agg_market)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m           .sort_values(['brier','logloss','n'], ascending=[True,True,False]))\n\u001b[32m     14\u001b[39m report\n",
      "\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7175\u001b[39m                 \u001b[33mf\"Length of ascending ({len(ascending)})\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7176\u001b[39m                 \u001b[33mf\" != length of by ({len(by)})\"\u001b[39m\n\u001b[32m   7177\u001b[39m             )\n\u001b[32m   7178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7179\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7180\u001b[39m \n\u001b[32m   7181\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7182\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m7179\u001b[39m         ...     key=\u001b[38;5;28;01mlambda\u001b[39;00m x: np.argsort(index_natsorted(df[\u001b[33m\"time\"\u001b[39m]))\n",
      "\u001b[32m~/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'brier'"
     ]
    }
   ],
   "source": [
    "def brier(y_true, p):\n",
    "    y_true = np.asarray(y_true, float); p = np.asarray(p, float)\n",
    "    return np.mean((p - y_true)**2)\n",
    "def logloss(y_true, p, eps=1e-9):\n",
    "    y_true = np.asarray(y_true, float); p = np.clip(np.asarray(p, float), eps, 1-eps)\n",
    "    return -np.mean(y_true*np.log(p) + (1-y_true)*np.log(1-p))\n",
    "def agg_market(g):\n",
    "    p = g['model_prob'].astype(float).values\n",
    "    y = g['actual'].astype(float).values\n",
    "    import pandas as pd, numpy as np\n",
    "    return pd.Series({'n':len(g), 'avg_pred':np.mean(p), 'base_rate':np.mean(y), 'brier':brier(y,p), 'logloss':logloss(y,p), 'abs_calib_gap':abs(np.mean(p)-np.mean(y))})\n",
    "report = (scored.groupby('market_std', as_index=False).apply(agg_market)\n",
    "          .sort_values(['brier','logloss','n'], ascending=[True,True,False]))\n",
    "report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42878689",
   "metadata": {},
   "source": [
    "## 7) Calibration tables (deciles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8a4661",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     out[\u001b[33m'\u001b[39m\u001b[33mabs_gap\u001b[39m\u001b[33m'\u001b[39m] = (out[\u001b[33m'\u001b[39m\u001b[33mp_avg\u001b[39m\u001b[33m'\u001b[39m] - out[\u001b[33m'\u001b[39m\u001b[33my_rate\u001b[39m\u001b[33m'\u001b[39m]).abs()\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m examples = (report.sort_values(\u001b[33m'\u001b[39m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[33m'\u001b[39m\u001b[33mmarket_std\u001b[39m\u001b[33m'\u001b[39m].head(\u001b[32m3\u001b[39m).tolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(report) \u001b[38;5;28;01melse\u001b[39;00m [])\n\u001b[32m      9\u001b[39m tables = {}\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m examples:\n",
      "\u001b[31mNameError\u001b[39m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "def calib_table(y_true, p, bins=10):\n",
    "    import pandas as pd, numpy as np\n",
    "    idx = np.clip((p * bins).astype(int), 0, bins-1)\n",
    "    df = pd.DataFrame({'bin':idx, 'p':p, 'y':y_true})\n",
    "    out = df.groupby('bin').agg(n=('y','size'), p_avg=('p','mean'), y_rate=('y','mean')).reset_index()\n",
    "    out['abs_gap'] = (out['p_avg'] - out['y_rate']).abs()\n",
    "    return out\n",
    "examples = (report.sort_values('n', ascending=False)['market_std'].head(3).tolist() if len(report) else [])\n",
    "tables = {}\n",
    "for m in examples:\n",
    "    sub = scored[scored['market_std']==m]\n",
    "    tables[m] = calib_table(sub['actual'].values.astype(float), sub['model_prob'].values.astype(float), bins=10)\n",
    "tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dca31-e572-4583-adac-500f195c67ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
