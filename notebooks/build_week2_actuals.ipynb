{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6c6c9e",
   "metadata": {},
   "source": [
    "# Build Week 2 Actuals\n",
    "\n",
    "This notebook derives Week 2 **actuals** for player props by joining your modeled props to weekly player stats and computing outcomes.\n",
    "\n",
    "**Inputs**\n",
    "- `data/props/props_with_model_week2.csv` (from your pipeline)\n",
    "- Weekly player stats file (one of):\n",
    "  - `data/weekly_player_stats_2025.parquet`\n",
    "  - `data/weekly_player_stats_2025.csv.gz`\n",
    "\n",
    "**Output**\n",
    "- `data/actuals/week2.csv` with:\n",
    "  - `player_key, market_std, point_key, side, actual_value, result`\n",
    "\n",
    "> Markets handled now: common O/U (yards/receptions/attempts/completions/TDs/INTs), and **anytime_td** (YES/NO). Markets like **first_td**, **longest reception/rush**, or exotic combos aren’t computed here yet and will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52d566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BASE] /Users/pwitt/fourth-and-value\n",
      "[props] shape: (2673, 24)\n",
      "[stats] shape: (1142, 114)\n",
      "[stats] after season/week filter: (71, 114)\n",
      "[join] props.player_key  ↔  stats.player_id\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "[ERR] props missing required column: side",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m [ERR] props missing required column: side\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pwitt/opt/anaconda3/envs/nfl2025/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "WEEK = 2\n",
    "SEASON = 2025\n",
    "\n",
    "# --- find repo base ---\n",
    "BASE = Path.cwd()\n",
    "for p in [BASE] + list(BASE.parents):\n",
    "    if (p/\"Makefile\").exists() and (p/\"data\").exists():\n",
    "        BASE = p; break\n",
    "print(\"[BASE]\", BASE)\n",
    "\n",
    "props_path = BASE / f\"data/props/props_with_model_week{WEEK}.csv\"\n",
    "stats_parq = BASE / \"data/weekly_player_stats_2025.parquet\"\n",
    "stats_csvz = BASE / \"data/weekly_player_stats_2025.csv.gz\"\n",
    "out_actuals = BASE / f\"data/actuals/week{WEEK}.csv\"\n",
    "\n",
    "if not props_path.exists():\n",
    "    raise SystemExit(f\"[ERR] missing props: {props_path}\")\n",
    "\n",
    "# load props\n",
    "dfp = pd.read_csv(props_path)\n",
    "print(\"[props] shape:\", dfp.shape)\n",
    "\n",
    "# load stats\n",
    "if stats_parq.exists():\n",
    "    dfs = pd.read_parquet(stats_parq)\n",
    "elif stats_csvz.exists():\n",
    "    dfs = pd.read_csv(stats_csvz)\n",
    "else:\n",
    "    raise SystemExit(\"[ERR] missing weekly player stats: expected data/weekly_player_stats_2025.parquet or .csv.gz\")\n",
    "\n",
    "print(\"[stats] shape:\", dfs.shape)\n",
    "\n",
    "# Normalize column names we expect\n",
    "# nflverse often uses 'season','week','player_id' (gsis_id or gsis_it_id), and stat fields like passing_yards, rushing_yards, etc.\n",
    "dfs_cols = {c.lower(): c for c in dfs.columns}\n",
    "def has(col): return col in dfs_cols\n",
    "def col(col): return dfs_cols[col]\n",
    "\n",
    "# Filter to target season/week if present\n",
    "if has(\"season\"): dfs = dfs[dfs[col(\"season\")] == SEASON]\n",
    "if has(\"week\"):   dfs = dfs[dfs[col(\"week\")] == WEEK]\n",
    "print(\"[stats] after season/week filter:\", dfs.shape)\n",
    "\n",
    "# choose join key\n",
    "# Prefer 'player_key' in props matching a stats id column. We try common id/name fallbacks.\n",
    "join_left = \"player_key\" if \"player_key\" in dfp.columns else None\n",
    "stats_id_candidates = [\"player_id\",\"gsis_id\",\"gsis_it_id\",\"nfl_id\",\"pfr_player_id\"]\n",
    "join_right = None\n",
    "for cand in stats_id_candidates:\n",
    "    if cand in dfs.columns:\n",
    "        join_right = cand; break\n",
    "\n",
    "# If we can't find id columns, fall back to player name (less reliable)\n",
    "if join_left is None or join_right is None:\n",
    "    print(\"[warn] falling back to name join; ensure names match between sources.\")\n",
    "    join_left = next((c for c in [\"player\",\"name\",\"player_name\"] if c in dfp.columns), None)\n",
    "    join_right = next((c for c in [\"player\",\"name\",\"player_name\",\"full_name\"] if c in dfs.columns), None)\n",
    "\n",
    "if join_left is None or join_right is None:\n",
    "    raise SystemExit(\"[ERR] no viable join keys between props and stats. Expected player_key/id or player/name.\")\n",
    "\n",
    "print(f\"[join] props.{join_left}  ↔  stats.{join_right}\")\n",
    "\n",
    "# Minimal columns we want from props\n",
    "need = [\"market_std\",\"side\"]\n",
    "for n in need:\n",
    "    if n not in dfp.columns:\n",
    "        raise SystemExit(f\"[ERR] props missing required column: {n}\")\n",
    "have_point = \"point_key\" in dfp.columns\n",
    "\n",
    "# Market mapping: market_std -> (stats_column, type)\n",
    "# type: 'count', 'yards', 'yesno', etc. Mainly used for clarity; logic below uses numeric comparison or >0 rules.\n",
    "# Aliases handled by including multiple keys.\n",
    "M = {}\n",
    "\n",
    "def add(keys, stat_col):\n",
    "    for k in keys:\n",
    "        M[k] = stat_col\n",
    "\n",
    "# Yards\n",
    "add([\"rush_yds\",\"rushing_yds\",\"rush_yards\",\"rushing_yards\"],         \"rushing_yards\")\n",
    "add([\"recv_yds\",\"reception_yds\",\"receiving_yards\"],                   \"receiving_yards\")\n",
    "add([\"pass_yds\",\"passing_yards\"],                                     \"passing_yards\")\n",
    "\n",
    "# Counts\n",
    "add([\"rec\",\"receptions\"],                                             \"receptions\")\n",
    "add([\"rush_att\",\"rush_attempts\",\"rushing_attempts\",\"carries\"],        \"rushing_attempts\")\n",
    "add([\"pass_cmp\",\"pass_completions\",\"completions\"],                    \"completions\")\n",
    "add([\"pass_att\",\"pass_attempts\"],                                     \"attempts\")\n",
    "add([\"pass_tds\",\"passing_tds\"],                                       \"passing_tds\")\n",
    "add([\"pass_ints\",\"pass_interceptions\",\"interceptions_thrown\"],        \"interceptions\")\n",
    "\n",
    "# Yes/No\n",
    "# 'anytime_td' => rushing_tds + receiving_tds > 0\n",
    "YESNO = {\"anytime_td\"}\n",
    "\n",
    "# Unsupported/derived later (skipped safely if present)\n",
    "UNSUPPORTED_PREFIX = (\"first_td\",\"first_team_td\",\"rush_longest\",\"reception_longest\",\"longest_reception\",\"longest_rush\")\n",
    "\n",
    "# Build stats helpers (handle missing columns by filling 0)\n",
    "def scol(df, name):\n",
    "    if name in df.columns: return df[name]\n",
    "    # Try lowercase lookup\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    if name.lower() in lc: return df[lc[name.lower()]]\n",
    "    # missing -> zeros\n",
    "    return 0\n",
    "\n",
    "# Prepare condensed stats with the columns we need\n",
    "needed_stats_cols = set([join_right, \"season\" if \"season\" in dfs.columns else None, \"week\" if \"week\" in dfs.columns else None])\n",
    "needed_stats_cols.discard(None)\n",
    "needed_stats_cols = set(needed_stats_cols)\n",
    "\n",
    "# union of referenced stat columns\n",
    "for mk, sc in M.items():\n",
    "    needed_stats_cols.add(sc)\n",
    "# yes/no extras\n",
    "needed_stats_cols.update([\"rushing_tds\",\"receiving_tds\",\"interceptions\"])\n",
    "\n",
    "dfs_small = dfs[[c for c in needed_stats_cols if c in dfs.columns]].copy()\n",
    "print(\"[stats] using columns:\", sorted(dfs_small.columns))\n",
    "\n",
    "# Join props to stats (left join, keep all props)\n",
    "dfj = dfp.merge(dfs_small, left_on=join_left, right_on=join_right, how=\"left\", suffixes=(\"\",\"_stat\"))\n",
    "print(\"[join] merged shape:\", dfj.shape)\n",
    "\n",
    "# Compute actual_value per row\n",
    "def actual_for_row(row):\n",
    "    m = str(row.get(\"market_std\",\"\")).strip().lower()\n",
    "    # skip unsupported\n",
    "    if m.startswith(UNSUPPORTED_PREFIX):\n",
    "        return None\n",
    "\n",
    "    if m in YESNO:\n",
    "        # anytime_td\n",
    "        td = 0\n",
    "        if \"rushing_tds\" in row and pd.notna(row[\"rushing_tds\"]): td += row[\"rushing_tds\"]\n",
    "        if \"receiving_tds\" in row and pd.notna(row[\"receiving_tds\"]): td += row[\"receiving_tds\"]\n",
    "        return float(td)\n",
    "\n",
    "    # map to a stats column\n",
    "    statcol = None\n",
    "    if m in M:\n",
    "        statcol = M[m]\n",
    "    else:\n",
    "        # try some gentle normalizations\n",
    "        m2 = m.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        if m2 in M: statcol = M[m2]\n",
    "    if statcol is None:\n",
    "        return None\n",
    "    val = row.get(statcol, None)\n",
    "    try:\n",
    "        return float(val) if pd.notna(val) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def decide_result(side, actual_value, point):\n",
    "    if actual_value is None:\n",
    "        return None\n",
    "    s = str(side).strip().lower()\n",
    "    if s in (\"yes\",\"no\"):\n",
    "        # yes/no markets: interpret threshold as >0 for YES\n",
    "        yes = (actual_value > 0)\n",
    "        return 1 if ((s == \"yes\" and yes) or (s == \"no\" and not yes)) else 0\n",
    "    # over/under with numeric point\n",
    "    try:\n",
    "        p = float(point) if point is not None else None\n",
    "    except Exception:\n",
    "        p = None\n",
    "    if p is None:\n",
    "        return None\n",
    "    if s == \"over\":\n",
    "        return 1 if actual_value >= p else 0\n",
    "    if s == \"under\":\n",
    "        return 1 if actual_value <= p else 0\n",
    "    return None\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# compute\n",
    "dfj[\"actual_value\"] = dfj.apply(actual_for_row, axis=1)\n",
    "\n",
    "point_col = \"point_key\" if have_point else None\n",
    "dfj[\"result\"] = [\n",
    "    decide_result(side=row[\"side\"], actual_value=row[\"actual_value\"], point=(row.get(point_col) if point_col else None))\n",
    "    for _, row in dfj.iterrows()\n",
    "]\n",
    "\n",
    "# Filter to rows where we produced an outcome or at least have an actual_value\n",
    "supported_mask = dfj[\"actual_value\"].notna()\n",
    "unsupported = (~supported_mask).sum()\n",
    "print(f\"[info] unsupported/unknown markets or missing stats rows skipped: {unsupported}\")\n",
    "\n",
    "out_cols = [\"player_key\",\"market_std\",\"side\",\"actual_value\",\"result\"]\n",
    "if have_point: out_cols.insert(2, \"point_key\")\n",
    "\n",
    "# Best-effort fill for player_key if missing\n",
    "if \"player_key\" not in dfj.columns and join_left in dfj.columns:\n",
    "    dfj[\"player_key\"] = dfj[join_left]\n",
    "\n",
    "out = dfj.loc[supported_mask, [c for c in out_cols if c in dfj.columns]].copy()\n",
    "\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(out_actuals, index=False)\n",
    "print(f\"[OK] wrote {len(out)} rows to {out_actuals}\")\n",
    "print(out.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624cee2-d180-47da-9226-ecb5445d0cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
